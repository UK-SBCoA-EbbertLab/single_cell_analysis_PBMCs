{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39197f89-2d53-48dd-82b3-819d7e27ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, platform, scanpy, anndata, polars as pl, pandas as pd\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"OS:\", platform.system(), platform.release())\n",
    "print(\"scanpy:\", scanpy.__version__)\n",
    "print(\"anndata:\", anndata.__version__)\n",
    "print(\"polars:\", pl.__version__)\n",
    "print(\"pandas:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac4936-404f-4744-9a97-af378436c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Read the GTF into a DataFrame\n",
    "gtf = pd.read_csv(\n",
    "    \"Homo_sapiens.GRCh38.113.gtf\",\n",
    "    sep=\"\\t\", # GTFs are tab-separated\n",
    "    comment=\"#\", # Skip header/comment lines beginning with '#'\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"seqname\", \"source\", \"feature\", \"start\", \"end\",\n",
    "        \"score\", \"strand\", \"frame\", \"attribute\"\n",
    "    ],\n",
    "    dtype={\"attribute\": str},\n",
    ")\n",
    "\n",
    "# Extract the fields we care about via regex on the 'attribute' column\n",
    "gtf[\"transcript_id\"] = gtf[\"attribute\"].str.extract(r'transcript_id \"([^\"]+)\"')\n",
    "gtf[\"gene_id\"] = gtf[\"attribute\"].str.extract(r'gene_id \"([^\"]+)\"')\n",
    "gtf[\"gene_name\"] = gtf[\"attribute\"].str.extract(r'gene_name \"([^\"]+)\"')\n",
    "\n",
    "# Filter for transcript‐level entries with valid ENSG/ENST IDs\n",
    "tx = (\n",
    "    gtf[\n",
    "        gtf[\"gene_id\"].str.startswith(\"ENSG\", na=False) &\n",
    "        gtf[\"transcript_id\"].str.startswith(\"ENST\", na=False)\n",
    "    ]\n",
    "    .loc[:, [\"transcript_id\", \"gene_id\", \"gene_name\"]]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Write out the transcript‐level table and sav\n",
    "tx.to_csv(\"transcript_annotation_key_info.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# --- If you also want the gene‐level table as in your earlier snippet: ---\n",
    "genes = (\n",
    "    gtf[\n",
    "        gtf[\"gene_id\"].str.startswith(\"ENSG\", na=False)\n",
    "    ]\n",
    "    .loc[:, [\"gene_id\", \"gene_name\"]]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "genes.to_csv(\"gene_annotation_key_info.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74faa3ba-2834-4f35-8178-7989063dbf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "#Utilize file from above\n",
    "gene_annot = pl.read_csv(\"gene_annotation_key_info.tsv\", separator=\"\\t\")\n",
    "\n",
    "# Extract gene IDs and gene names\n",
    "gene_ids = gene_annot.get_column(\"gene_id\").to_list()\n",
    "gene_names = gene_annot.get_column(\"gene_name\").to_list()\n",
    "\n",
    "# Construct first row: header label + all gene IDs\n",
    "row_1 = [\"gene_ids\"] + gene_ids\n",
    "\n",
    "# Construct second row: header label + all gene names\n",
    "row_2 = [\"gene_name\"] + gene_names\n",
    "\n",
    "# Build dictionary: column index → [row_1_value, row_2_value]\n",
    "row_dict = {f\"col_{i}\": [row_1[i], row_2[i]] for i in range(len(row_1))}\n",
    "\n",
    "# Create DataFrame: 2 rows, many columns\n",
    "transposed_df = pl.DataFrame(row_dict)\n",
    "\n",
    "# Save as TSV\n",
    "transposed_df.write_csv(\"gene_annotation_key_info_transposed.tsv\", separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10cef85-c0a9-4c51-ad22-0b46a1087720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "\n",
    "def snag_and_write_gene_ids_row_with_label(txt_paths, output_dir):\n",
    "    \"\"\"\n",
    "    For each .txt file:\n",
    "    - Read using enforced schema (CellID as Utf8, all else as Float64)\n",
    "    - Save full dataframe as .parquet\n",
    "    - Create a single horizontal row:\n",
    "        - First cell: 'GENEIDs'\n",
    "        - Remaining cells: gene IDs from transposed data\n",
    "    - Save this single-row labeled gene ID row as .parquet\n",
    "    \"\"\"\n",
    "    for path in txt_paths:\n",
    "        sample_name = os.path.basename(path).replace(\".txt\", \"\")\n",
    "        print(f\"🔍 Reading: {sample_name}\")\n",
    "\n",
    "        # STEP 1: Load header to get column names\n",
    "        with open(path, 'r') as f:\n",
    "            header_line = f.readline().strip()\n",
    "\n",
    "        columns = header_line.split(\"\\t\")\n",
    "\n",
    "        # STEP 2: Build schema override\n",
    "        schema_overrides = {\"CellID\": pl.Utf8}\n",
    "        schema_overrides.update({col: pl.Float64 for col in columns if col != \"CellID\"})\n",
    "\n",
    "        # STEP 3: Load file using enforced schema\n",
    "        df = pl.read_csv(\n",
    "            path,\n",
    "            separator=\"\\t\",\n",
    "            schema_overrides=schema_overrides,\n",
    "            infer_schema_length=0,  # Disable inference of datatypes by Polars\n",
    "            try_parse_dates=False\n",
    "        )\n",
    "\n",
    "        # STEP 4: Save full dataframe as parquet\n",
    "        parquet_out_path = os.path.join(output_dir, f\"{sample_name}.parquet\")\n",
    "        df.write_parquet(parquet_out_path, compression=\"zstd\", compression_level=4)\n",
    "        print(f\"✅ Saved full dataset to: {parquet_out_path}\")\n",
    "\n",
    "        # STEP 5: Create single-row DataFrame of GENEIDs\n",
    "        gene_ids = [col for col in df.columns if col != \"CellID\"]\n",
    "        row_dict = {f\"col_{i}\": [val] for i, val in enumerate([\"GENEIDs\"] + gene_ids)}\n",
    "        id_df = pl.DataFrame(row_dict)\n",
    "\n",
    "        # STEP 6: Save gene ID row as parquet\n",
    "        ids_out_path = os.path.join(output_dir, f\"gene_IDs_{sample_name}.parquet\")\n",
    "        id_df.write_parquet(ids_out_path, compression=\"zstd\", compression_level=4)\n",
    "        print(f\"✅ Saved labeled gene IDs row to: {ids_out_path}\")\n",
    "\n",
    "    print(f\"🎉 Finished processing {len(txt_paths)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481b3cf-34ad-4f8d-a3cd-a2f63df294ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use function on gene files\n",
    "gene_files = [\n",
    "    \"InitialFiltering/PBMC_patient0_JUNE_16_2025_bambu_quant_PBMC1_combined_counts_gene.filtered_transposed_expression_matrix.txt\",\n",
    "    \"InitialFiltering. /PBMC_patient0_JUNE_16_2025_bambu_quant_PBMC2_combined_counts_gene.filtered_transposed_expression_matrix.txt\"\n",
    "]\n",
    "\n",
    "snag_and_write_gene_ids_row_with_label(gene_files, output_dir=\"Parquet_Files/RawData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f93235-c8e5-422f-87ed-2d37d17d97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_annot = pl.read_csv(\"gene_annotation_key_info_transposed.tsv\", separator=\"\\t\")\n",
    "\n",
    "split_folder = \"Parquet_Files/RawData\"\n",
    "PBMC1_gene_id = pl.read_parquet(os.path.join(split_folder, \"gene_IDs_PBMC_patient0_JUNE_16_2025_bambu_quant_PBMC1_combined_counts_gene.filtered_transposed_expression_matrix.parquet\"))\n",
    "PBMC2_gene_id = pl.read_parquet(os.path.join(split_folder, \"gene_IDs_PBMC_patient0_JUNE_16_2025_bambu_quant_PBMC2_combined_counts_gene.filtered_transposed_expression_matrix.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669b8e9-0e24-466f-8e42-517908db342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_gene_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0963f2e3-31f8-4bed-9732-e06f65313eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_annot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a473661-ef38-43f3-a0b0-343b3e9b143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_gene_ids_from_row(row_df: pl.DataFrame, id_to_name: dict) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a single-row DataFrame of gene IDs, return a two-column DataFrame:\n",
    "    - GENEID\n",
    "    - GENE_NAME\n",
    "    \"\"\"\n",
    "    # Extract the first (and only) row from the DataFrame as a list of gene IDs\n",
    "    gene_ids = row_df.row(0) \n",
    "\n",
    "    # Optionally skip the first entry if it's a label like 'GENEIDs'\n",
    "    if gene_ids[0] == \"GENEIDs\": # Check if the first element is a label string, not a real ID\n",
    "        gene_ids = gene_ids[1:] # Skip that label to keep only gene IDs\n",
    "\n",
    "    # Map each gene ID to its corresponding gene name; use None if not found\n",
    "    gene_names = [id_to_name.get(gid, None) for gid in gene_ids]\n",
    "\n",
    "    # Create new DataFrame pairing each gene ID with its gene name\n",
    "    annotated_df = pl.DataFrame({\n",
    "        \"GENEID\": gene_ids,\n",
    "        \"GENE_NAME\": gene_names\n",
    "    })\n",
    "\n",
    "    return annotated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29426ae9-526c-4a04-933c-bac8fa114003",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Convert gene_annot to a Lookup table:\n",
    "# Extract gene IDs and gene names from gene_annot\n",
    "gene_ids = gene_annot.row(0)[1:]   # Skip the \"gene_ids\" label\n",
    "gene_names = gene_annot.row(1)[1:] # Skip the \"gene_name\" label\n",
    "\n",
    "# Create dictionary: gene_id → gene_name\n",
    "id_to_name = dict(zip(gene_ids, gene_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac284d44-c825-4ff0-9e9d-9e4b329c1d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate PBMC1 and PBMC2 single-row DataFrames using lookup\n",
    "\n",
    "PBMC1_gene_annotated = annotate_gene_ids_from_row(PBMC1_gene_id, id_to_name)\n",
    "PBMC2_gene_annotated = annotate_gene_ids_from_row(PBMC2_gene_id, id_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad2c71c-a7bc-4442-9a59-0473aafadb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_gene_annotated.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f4611e-473a-4d7f-aef9-eae0af8f3af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing gene names with empty string to prevent NaN values in merged outputs\n",
    "PBMC1_gene_annotated = PBMC1_gene_annotated.with_columns(\n",
    "    pl.col(\"GENE_NAME\").fill_null(\"\") # Replace nulls with empty string\n",
    ")\n",
    "\n",
    "PBMC2_gene_annotated = PBMC2_gene_annotated.with_columns(\n",
    "    pl.col(\"GENE_NAME\").fill_null(\"\") # Replace nulls with empty string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbee123-1f26-4847-8ee0-341554050edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_gene_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c774bc21-0e20-4c51-9651-c064fb89e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotated tables\n",
    "split_folder = \"Parquet_Files/IntermediateFiles\"\n",
    "PBMC1_gene_annotated.write_parquet(os.path.join(split_folder, \"annotated_gene_IDs_PBMC1.parquet\"), compression=\"zstd\")\n",
    "PBMC2_gene_annotated.write_parquet(os.path.join(split_folder, \"annotated_gene_IDs_PBMC2.parquet\"), compression=\"zstd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d7630-d8f7-431a-9b9d-8193e96058fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d947e-f4dd-4cdb-a1dc-3bf32f1f99cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b34dddc-a9ad-4ef7-8d66-08cc45de3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "split_folder = \"Parquet_Files/IntermediateFiles\"\n",
    "# Load annotated Parquet files using Polars, then convert to Pandas DataFrames\n",
    "PBMC1_gene_anno = pl.read_parquet(os.path.join(split_folder, \"annotated_gene_IDs_PBMC1.parquet\")).to_pandas()\n",
    "PBMC2_gene_anno = pl.read_parquet(os.path.join(split_folder, \"annotated_gene_IDs_PBMC2.parquet\")).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40464b27-9d80-4d2a-9f58-fa0170a83286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_gene_id(geneid: str, symbol: str) -> str:\n",
    "    geneid = (geneid or \"\").strip() # Ensure non-null string and remove extra spaces\n",
    "    symbol = (symbol or \"\").strip() # Ensure non-null string and remove extra spaces\n",
    "\n",
    "    if geneid.startswith(\"ENSG\"):\n",
    "        return f\"{symbol}:{geneid}\" if symbol else geneid # Combine symbol:ID if symbol exists; else use ID only\n",
    "    else:\n",
    "        return f\"{symbol}:{geneid}\" if symbol else geneid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbd9502-3610-4c5c-a9cc-3a3105468a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the combination function row-wise to both dataframes\n",
    "PBMC1_gene_anno[\"combined_ID\"] = PBMC1_gene_anno.apply(\n",
    "    lambda row: create_combined_gene_id(row[\"GENEID\"], row[\"GENE_NAME\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "PBMC2_gene_anno[\"combined_ID\"] = PBMC2_gene_anno.apply(\n",
    "    lambda row: create_combined_gene_id(row[\"GENEID\"], row[\"GENE_NAME\"]),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56813a9a-a25f-44f3-846f-22cdf461d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that combined_ID was created with GENE_NAME:GENEID, if GENE_NAME has contents\n",
    "#If not, combined_ID will only contain GENEID\n",
    "PBMC1_gene_anno.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e3c07-012e-471b-85e1-d40e3bef789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outputs\n",
    "split_folder = \"Parquet_Files/IntermediateFiles\"\n",
    "PBMC1_gene_anno.to_parquet(os.path.join(split_folder, \"PBMC1_gene_IDs_with_combined.parquet\"), compression=\"zstd\")\n",
    "PBMC2_gene_anno.to_parquet(os.path.join(split_folder, \"PBMC2_gene_IDs_with_combined.parquet\"), compression=\"zstd\")\n",
    "print(\"✅ Combined ID columns created and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417df6cf-66b7-4e92-b0c3-14c055715efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f91378-cd44-4d93-b033-faad011c6918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf3cee-fd09-4745-91a7-758e33bbc201",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_folder = \"Parquet_Files/RawData\"\n",
    "\n",
    "# Step 4: Load the updated annotated and sorted data\n",
    "PBMC1_gene = pd.read_parquet(os.path.join(split_folder, \"PBMC_patient0_JUNE_16_2025_bambu_quant_PBMC1_combined_counts_gene.filtered_transposed_expression_matrix.parquet\"))\n",
    "PBMC2_gene = pd.read_parquet(os.path.join(split_folder, \"PBMC_patient0_JUNE_16_2025_bambu_quant_PBMC2_combined_counts_gene.filtered_transposed_expression_matrix.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db21c9-ec99-496b-8129-e5803e7aa39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_gene.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7fdf84-a87b-4b06-a175-f035376d9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_gene.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f490cbf-03bd-48e0-9573-54a4c546adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_gene_anno.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd7543-3840-41d3-9a87-7518b3529433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE INSERTING combined_IDs, validate row alignment\n",
    "# Get the gene columns from PBMC1_gene, excluding CellID\n",
    "pbmc1_columns = [col for col in PBMC1_gene.columns if col != \"CellID\"]\n",
    "\n",
    "# Get GENEID list from PBMC1_gene_anno\n",
    "pbmc1_geneids = PBMC1_gene_anno[\"GENEID\"].tolist()\n",
    "\n",
    "# Assert that column names match GENEID list\n",
    "assert pbmc1_columns == pbmc1_geneids, \"PBMC1_gene_id mismatch\"\n",
    "\n",
    "print(\"✅ PBMC1 gene columns aligned with annotation IDs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dec11d-c2f0-4f78-bc93-58448544803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the gene columns from PBMC1_gene, excluding CellID\n",
    "pbmc2_columns = [col for col in PBMC2_gene.columns if col != \"CellID\"]\n",
    "\n",
    "# Get GENEID list from PBMC1_gene_anno\n",
    "pbmc2_geneids = PBMC2_gene_anno[\"GENEID\"].tolist()\n",
    "\n",
    "# Assert that column names match GENEID list\n",
    "assert pbmc2_columns == pbmc2_geneids, \"PBMC2_gene_id mismatch\"\n",
    "\n",
    "print(\"✅ PBMC2 gene columns aligned with annotation IDs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f05145e-1670-41b3-91ec-1f545c474093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare first row: 'combined_IDs' followed by combined IDs\n",
    "first_row = pd.Series([\"combined_IDs\"] + PBMC1_gene_anno[\"combined_ID\"].tolist(), index=PBMC1_gene.columns)\n",
    "first_row_2 = pd.Series([\"combined_IDs\"] + PBMC2_gene_anno[\"combined_ID\"].tolist(), index=PBMC2_gene.columns)\n",
    "\n",
    "# Prepend this row to PBMC1_gene or PBMC2_gene\n",
    "PBMC1_gene_with_row = pd.concat([first_row.to_frame().T, PBMC1_gene], ignore_index=True)\n",
    "PBMC2_gene_with_row = pd.concat([first_row_2.to_frame().T, PBMC2_gene], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2723f03-cd37-4f38-81af-f81dd0014b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_gene_with_row.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e236046c-f36e-46d2-86d3-c8477bfba7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC2_gene_with_row.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee91c6-b488-4b88-862c-521700b03fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign new headers\n",
    "PBMC1_gene.columns = [\"CellID\"] + PBMC1_gene_anno[\"combined_ID\"].tolist()\n",
    "PBMC2_gene.columns = [\"CellID\"] + PBMC2_gene_anno[\"combined_ID\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f600a6-72dc-4c4f-94ce-b35fb1a86db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_gene.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6cb64-0714-4bf5-92f2-bbd0de1bc04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC2_gene.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1dab44-4438-49dc-83f3-f224e29f173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotated matrices\n",
    "split_folder = \"Parquet_Files/IntermediateFiles\"\n",
    "\n",
    "PBMC1_gene.to_parquet(os.path.join(split_folder, \"PBMC1_gene_expr_annotated.parquet\"), compression=\"zstd\")\n",
    "PBMC2_gene.to_parquet(os.path.join(split_folder, \"PBMC2_gene_expr_annotated.parquet\"), compression=\"zstd\")\n",
    "\n",
    "print(\"✅ Annotated gene expression matrices saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1576e3-b248-43b5-a133-3721e1810d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a759e-ad49-4582-89c9-44b3dc1d9b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624198b4-1cd3-4277-b57e-83a6490ec83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Load raw isoform annotation table\n",
    "iso_annot = pl.read_csv(\"transcript_annotation_key_info.tsv\", separator=\"\\t\")\n",
    "\n",
    "# Extract TXNames and GeneIDs\n",
    "tx_names = iso_annot.get_column(\"transcript_id\").to_list()\n",
    "gene_ids = iso_annot.get_column(\"gene_id\").to_list()\n",
    "gene_names = iso_annot.get_column(\"gene_name\").to_list()\n",
    "\n",
    "# Row 1: header label + TXNames\n",
    "row_1 = [\"transcript_id\"] + tx_names\n",
    "\n",
    "# Row 2: header label + gene_ids\n",
    "row_2 = [\"gene_id\"] + gene_ids\n",
    "\n",
    "# Row 3: header label + gene_ids\n",
    "row_3 = [\"gene_name\"] + gene_names\n",
    "\n",
    "# Build transposed table: 2 rows, many columns\n",
    "row_dict = {f\"col_{i}\": [row_1[i], row_2[i], row_3[i]] for i in range(len(row_1))}\n",
    "\n",
    "# Create dataframe\n",
    "transposed_iso_annot = pl.DataFrame(row_dict)\n",
    "\n",
    "# Save transposed annotation\n",
    "transposed_iso_annot.write_csv(\"transcript_annotation_key_info_transposed.tsv\", separator=\"\\t\")\n",
    "print(\"✅ Isoform annotation transposed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc27d2f6-11ce-47a3-953b-dbcefb8ec018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "\n",
    "def snag_and_write_isoform_ids_row_with_label(txt_paths, output_dir):\n",
    "    \"\"\"\n",
    "    For each .txt file:\n",
    "    - Read using enforced schema (CellID as Utf8, all else as Float64)\n",
    "    - Save full dataframe as .parquet\n",
    "    - Create a two-row DataFrame:\n",
    "        - Row 1: 'TXID', followed by TXID from column names\n",
    "        - Row 2: 'GENEID', followed by GENEID from column names\n",
    "    - Save this two-row isoform ID annotation as .parquet\n",
    "    \"\"\"\n",
    "    for path in txt_paths:\n",
    "        sample_name = os.path.basename(path).replace(\".txt\", \"\")\n",
    "        print(f\"🔍 Reading: {sample_name}\")\n",
    "\n",
    "        # STEP 1: Load header to get column names\n",
    "        with open(path, 'r') as f:\n",
    "            header_line = f.readline().strip()\n",
    "\n",
    "        columns = header_line.split(\"\\t\")\n",
    "\n",
    "        # STEP 2: Build schema override\n",
    "        schema_overrides = {\"CellID\": pl.Utf8}\n",
    "        schema_overrides.update({col: pl.Float64 for col in columns if col != \"CellID\"})\n",
    "\n",
    "        # STEP 3: Load file with enforced schema\n",
    "        df = pl.read_csv(\n",
    "            path,\n",
    "            separator=\"\\t\",\n",
    "            schema_overrides=schema_overrides,\n",
    "            infer_schema_length=0,\n",
    "            try_parse_dates=False\n",
    "        )\n",
    "\n",
    "        # STEP 4: Save full dataframe as parquet\n",
    "        parquet_out_path = os.path.join(output_dir, f\"{sample_name}.parquet\")\n",
    "        df.write_parquet(parquet_out_path, compression=\"zstd\", compression_level=4)\n",
    "        print(f\"✅ Saved full dataset to: {parquet_out_path}\")\n",
    "\n",
    "        # STEP 5: Parse TXID and GENEID\n",
    "        tx_columns = [col for col in df.columns if col != \"CellID\"]\n",
    "        tx_ids = [col.split(\"|\")[0] for col in tx_columns]\n",
    "        gene_ids = [col.split(\"|\")[1] if \"|\" in col else None for col in tx_columns]\n",
    "\n",
    "        row_1 = [\"TXID\"] + tx_ids\n",
    "        row_2 = [\"GENEID\"] + gene_ids\n",
    "\n",
    "        # Build two-row DataFrame\n",
    "        row_dict = {f\"col_{i}\": [row_1[i], row_2[i]] for i in range(len(row_1))}\n",
    "        id_df = pl.DataFrame(row_dict)\n",
    "\n",
    "        # STEP 6: Save isoform ID annotation as parquet\n",
    "        ids_out_path = os.path.join(output_dir, f\"isoform_IDs_{sample_name}.parquet\")\n",
    "        id_df.write_parquet(ids_out_path, compression=\"zstd\", compression_level=4)\n",
    "        print(f\"✅ Saved TXID + GENEID row to: {ids_out_path}\")\n",
    "\n",
    "    print(f\"🎉 Finished processing {len(txt_paths)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c204255b-b0ab-49b1-9305-d01814ccbefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use function on gene files\n",
    "iso_files = [\n",
    "     \"InitialFiltering/PBMC_patient0_JUNE_16_2025_bambu_quant_PBMC1_combined_counts_transcript.filtered_transposed_expression_matrix.txt\",\n",
    "     \"InitialFiltering/PBMC_patient0_JUNE_16_2025_bambu_quant_PBMC2_combined_counts_transcript.filtered_transposed_expression_matrix.txt\"\n",
    "]\n",
    "\n",
    "snag_and_write_isoform_ids_row_with_label(iso_files, output_dir=\"Parquet_Files/RawData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7699f-4996-47c8-bdfb-2f7607e977cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_folder = \"Parquet_Files/RawData\"\n",
    "PBMC1_iso_id = pl.read_parquet(os.path.join(split_folder, \"isoform_IDs_PBMC_patient0_JUNE_16_2025_bambu_quant_PBMC1_combined_counts_transcript.filtered_transposed_expression_matrix.parquet\"))\n",
    "PBMC2_iso_id = pl.read_parquet(os.path.join(split_folder, \"isoform_IDs_PBMC_patient0_JUNE_16_2025_bambu_quant_PBMC2_combined_counts_transcript.filtered_transposed_expression_matrix.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e6212-bc53-423c-8aab-862cdd21f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_iso_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11e583-4086-4374-a0ff-b8e51a4c200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Load the original, clean annotation file\n",
    "iso_annot = pl.read_csv(\"transcript_annotation_key_info.tsv\", separator=\"\\t\")\n",
    "\n",
    "# Build dictionary: transcript_id → (gene_id, gene_name)\n",
    "tx_to_gene = {\n",
    "    tx: (gid, gname)\n",
    "    for tx, gid, gname in zip(\n",
    "        iso_annot[\"transcript_id\"],\n",
    "        iso_annot[\"gene_id\"],\n",
    "        iso_annot[\"gene_name\"]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5d861-a140-494e-b40c-a0a87728e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From your isoform annotation table\n",
    "tx_to_gene_info = dict(zip(\n",
    "    iso_annot[\"transcript_id\"].to_list(),\n",
    "    zip(iso_annot[\"gene_id\"].to_list(), iso_annot[\"gene_name\"].to_list())\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d64323-89c2-40c3-a867-e66ea491eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_isoform_ids_from_row(row_df: pl.DataFrame, tx_to_gene_info: dict) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a 2- or 3-row wide DataFrame with TXID, GENEID (and optionally GENE_NAME),\n",
    "    convert to a long-format table with columns: TXID, GENEID, GENE_NAME\n",
    "    \"\"\"\n",
    "    # Get each row as list\n",
    "    tx_ids = row_df.row(0)[1:]   # skip 'TXID'\n",
    "    gene_ids = row_df.row(1)[1:] # skip 'GENEID'\n",
    "\n",
    "    # Look up gene names\n",
    "    gene_names = []\n",
    "    for tx in tx_ids:\n",
    "        _, gene_name = tx_to_gene_info.get(tx, (None, None))\n",
    "        gene_names.append(gene_name)\n",
    "\n",
    "    # Build long-format DataFrame\n",
    "    df = pl.DataFrame({\n",
    "        \"TXID\": tx_ids,\n",
    "        \"GENEID\": gene_ids,\n",
    "        \"GENE_NAME\": gene_names\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612ffea-4007-4964-a224-acaddb9dac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_iso_annotated = annotate_isoform_ids_from_row(PBMC1_iso_id, tx_to_gene)\n",
    "PBMC2_iso_annotated = annotate_isoform_ids_from_row(PBMC2_iso_id, tx_to_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e31947-cc56-4bfc-b4ad-905c0748637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_iso_annotated.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f1116e-0d47-4f8b-b56c-96e5c724821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then fill in missing gene names with empty string (not NaN) to avoid NaNs in combined_ID\n",
    "PBMC1_iso_annotated = PBMC1_iso_annotated.with_columns(\n",
    "    pl.col(\"GENE_NAME\").fill_null(\"\")\n",
    ")\n",
    "\n",
    "PBMC2_iso_annotated = PBMC2_iso_annotated.with_columns(\n",
    "    pl.col(\"GENE_NAME\").fill_null(\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e228b-7403-449d-b934-b122b2e5efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_iso_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc76345a-0ad2-4c23-b622-fab11d5003bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotated tables\n",
    "split_folder = \"Parquet_Files/IntermediateFiles\"\n",
    "PBMC1_iso_annotated.write_parquet(os.path.join(split_folder, \"annotated_iso_IDs_PBMC1.parquet\"), compression=\"zstd\")\n",
    "PBMC2_iso_annotated.write_parquet(os.path.join(split_folder, \"annotated_iso_IDs_PBMC2.parquet\"), compression=\"zstd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7d5d79-cff4-48ff-b4c9-c2cce36ff085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "split_folder = \"Parquet_Files/IntermediateFiles\"\n",
    "# Load annotated files as pandas\n",
    "PBMC1_iso_anno = pl.read_parquet(os.path.join(split_folder, \"annotated_iso_IDs_PBMC1.parquet\")).to_pandas()\n",
    "PBMC2_iso_anno = pl.read_parquet(os.path.join(split_folder, \"annotated_iso_IDs_PBMC2.parquet\")).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf1041b-c800-46f6-80af-753b5ef33bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_combined_gene_id(geneid: str, symbol: str, txname: str) -> str:\n",
    "    symbol = (symbol or \"\").strip()\n",
    "    geneid = (geneid or \"\").strip()\n",
    "    txname = (txname or \"\").strip()\n",
    "\n",
    "    if geneid.startswith(\"ENSG\"):\n",
    "        return f\"{symbol}:{geneid}:{txname}\" if symbol else  f\"{geneid}:{txname}\"\n",
    "    else:\n",
    "        return f\"{symbol}:{geneid}: {txname}\" if symbol else f\"{geneid}:{txname}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13733a5-1907-4dc9-96fe-61ecc86e17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply row-wise in Pandas:\n",
    "PBMC1_iso_anno[\"combined_ID\"] = PBMC1_iso_anno.apply(\n",
    "    lambda row: create_combined_gene_id(row[\"GENEID\"], row[\"GENE_NAME\"], row[\"TXID\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "PBMC2_iso_anno[\"combined_ID\"] = PBMC2_iso_anno.apply(\n",
    "    lambda row: create_combined_gene_id(row[\"GENEID\"], row[\"GENE_NAME\"], row[\"TXID\"]),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b924727e-8558-432a-bb4e-b0c5a1892e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_iso_anno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7689d7-78d4-46b8-816f-12e7688827c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_iso_anno.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2faec-c42c-4cb6-aa95-37c120720708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outputs\n",
    "split_folder = \"Parquet_Files/IntermediateFiles\"\n",
    "PBMC1_iso_anno.to_parquet(os.path.join(split_folder, \"PBMC1_iso_IDs_with_combined.parquet\"), compression=\"zstd\")\n",
    "PBMC2_iso_anno.to_parquet(os.path.join(split_folder, \"PBMC2_iso_IDs_with_combined.parquet\"), compression=\"zstd\")\n",
    "print(\"✅ Combined ID columns created and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d756e7-d95f-4b40-a61c-6e7ac6c77af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_folder = \"Parquet_Files/RawData\"  # Update this if your path is different\n",
    "split_dir = \"Parquet_Files/IntermediateFiles\"  # Update this if your path is different\n",
    "\n",
    "# Step 4: Load the data\n",
    "PBMC1_iso = pd.read_parquet(os.path.join(split_folder, \"PBMC_patient0_JUNE_16_2025_bambu_quant_PBMC1_combined_counts_transcript.filtered_transposed_expression_matrix.parquet\"))\n",
    "PBMC2_iso = pd.read_parquet(os.path.join(split_folder, \"PBMC_patient0_JUNE_16_2025_bambu_quant_PBMC2_combined_counts_transcript.filtered_transposed_expression_matrix.parquet\"))\n",
    "PBMC1_iso_anno = pd.read_parquet(os.path.join(split_dir, \"PBMC1_iso_IDs_with_combined.parquet\"))\n",
    "PBMC2_iso_anno = pd.read_parquet(os.path.join(split_dir, \"PBMC2_iso_IDs_with_combined.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb19c4-dfc9-403c-9449-f85de1caee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PBMC1_iso.shape)\n",
    "print(PBMC1_iso_anno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee51d78-e6e4-403d-9e96-fb75952b185e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PBMC1_iso.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4ce098-d315-4521-8129-c9b136851011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PBMC1_iso_anno.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada1ada-f923-476b-aa28-24984b1cf0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PBMC2_iso.shape)\n",
    "print(PBMC2_iso_anno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5e310-ae3e-42e2-9907-775867e74728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE INSERTING combined_IDs, validate row alignment\n",
    "# Get the gene columns from PBMC1_iso, excluding CellID\n",
    "pbmc1_columns_full = [col for col in PBMC1_iso.columns if col != \"CellID\"]\n",
    "\n",
    "# Extract only the isoform names before \"|\" for matching\n",
    "pbmc1_columns = [col.split(\"|\")[0] for col in pbmc1_columns_full]\n",
    "\n",
    "# Get isoform IDs from annotation table\n",
    "pbmc1_isoids = PBMC1_iso_anno[\"TXID\"].tolist()\n",
    "\n",
    "# Validate alignment\n",
    "assert pbmc1_columns == pbmc1_isoids, \"❌ PBMC1 isoform IDs do not align with matrix columns\"\n",
    "\n",
    "print(\"✅ PBMC1 isoform columns aligned with annotation IDs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e38310-3651-4971-8825-abe44297ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE INSERTING combined_IDs, validate row alignment\n",
    "# Get the gene columns from PBMC1_iso, excluding CellID\n",
    "pbmc2_columns_full = [col for col in PBMC2_iso.columns if col != \"CellID\"]\n",
    "\n",
    "# Extract only the isoform names before \"|\" for matching\n",
    "pbmc2_columns = [col.split(\"|\")[0] for col in pbmc2_columns_full]\n",
    "\n",
    "# Get isoform IDs from annotation table\n",
    "pbmc2_isoids = PBMC2_iso_anno[\"TXID\"].tolist()\n",
    "\n",
    "# Validate alignment\n",
    "assert pbmc2_columns == pbmc2_isoids, \"❌ PBMC2 isoform IDs do not align with matrix columns\"\n",
    "\n",
    "print(\"✅ PBMC2 isoform columns aligned with annotation IDs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5360c9e-fee0-4d35-af8b-dbba6158cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare first row: 'combined_IDs' followed by combined IDs\n",
    "first_row = pd.Series([\"combined_IDs\"] + PBMC1_iso_anno[\"combined_ID\"].tolist(), index=PBMC1_iso.columns)\n",
    "\n",
    "\n",
    "# Prepend this row to PBMC1_iso or PBMC2_iso\n",
    "PBMC1_iso_with_row = pd.concat([first_row.to_frame().T, PBMC1_iso], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97c3e1-3766-4435-ad96-28f03d69eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = pd.Series([\"combined_IDs\"] + PBMC2_iso_anno[\"combined_ID\"].tolist(), index=PBMC2_iso.columns)\n",
    "PBMC2_iso_with_row = pd.concat([first_row.to_frame().T, PBMC2_iso], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4611e7ca-6910-48c9-8f76-c800f9b080e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_iso_with_row.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b931ff-6ed6-4dc5-ac65-88f344dc4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC2_iso_with_row.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf2e47-263b-426d-8532-3a835a41ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign new headers\n",
    "PBMC1_iso.columns = [\"CellID\"] + PBMC1_iso_anno[\"combined_ID\"].tolist()\n",
    "PBMC2_iso.columns = [\"CellID\"] + PBMC2_iso_anno[\"combined_ID\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b172c-2733-443c-b2f3-93b60c4afc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC1_iso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c8182-8f43-4faa-8aa1-2f47c7961d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC2_iso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133198d5-6631-4c76-a959-aa774e32b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotated matrices\n",
    "split_folder = \"Parquet_Files/IntermediateFiles\"\n",
    "\n",
    "PBMC1_iso.to_parquet(os.path.join(split_folder, \"PBMC1_iso_expr_annotated.parquet\"), compression=\"zstd\")\n",
    "PBMC2_iso.to_parquet(os.path.join(split_folder, \"PBMC2_iso_expr_annotated.parquet\"), compression=\"zstd\")\n",
    "\n",
    "print(\"✅ Annotated gene expression matrices saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed2823-2910-4ee5-811a-80454205871b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8adc12-d987-45ef-94ea-dc134705398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "# Load your annotated expression matrix\n",
    "df = pl.read_parquet(\"Parquet_Files/IntermediateFiles/PBMC1_iso_expr_annotated.parquet\")\n",
    "\n",
    "# Extract cell IDs (obs) and expression matrix (X)\n",
    "obs = pl.DataFrame({\"cell_id\": df[\"CellID\"]}).to_pandas().set_index(\"cell_id\")\n",
    "X = df.drop(\"CellID\").to_numpy()\n",
    "\n",
    "# Extract var: the column names *are* the combined IDs\n",
    "combined_ids = df.columns[1:]  # skip \"CellID\"\n",
    "var = pl.DataFrame({\"combined_id\": combined_ids}).to_pandas().set_index(\"combined_id\")\n",
    "\n",
    "# Create AnnData\n",
    "adata = ad.AnnData(X=X, obs=obs, var=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fc81d8-5bd4-4b09-be02-3ff33624bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic summary\n",
    "print(adata)\n",
    "\n",
    "# View cell metadata\n",
    "print(adata.obs.head())\n",
    "\n",
    "# View feature (gene/transcript) metadata\n",
    "print(adata.var.head())\n",
    "\n",
    "# View expression matrix shape or a slice\n",
    "print(adata.X.shape)\n",
    "print(adata.X[:5, :5])  # first 5 cells × first 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a55068-a267-4d47-9312-485f66543fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save (optional) ===\n",
    "adata.write_h5ad(\"Intermediate_Files/QC_07232025/PBMC1_iso_AnnData.h5ad\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbcfc7d-7e87-486c-8945-67eb7a274537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "# Load your annotated expression matrix\n",
    "df = pl.read_parquet(\"Parquet_Files/IntermediateFiles/PBMC2_iso_expr_annotated.parquet\")\n",
    "\n",
    "# Extract cell IDs (obs) and expression matrix (X)\n",
    "obs = pl.DataFrame({\"cell_id\": df[\"CellID\"]}).to_pandas().set_index(\"cell_id\")\n",
    "X = df.drop(\"CellID\").to_numpy()\n",
    "\n",
    "# Extract var: the column names *are* the combined IDs\n",
    "combined_ids = df.columns[1:]  # skip \"CellID\"\n",
    "var = pl.DataFrame({\"combined_id\": combined_ids}).to_pandas().set_index(\"combined_id\")\n",
    "\n",
    "# Create AnnData\n",
    "adata = ad.AnnData(X=X, obs=obs, var=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b2a66-8ebb-4f00-9b21-cef66317de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic summary\n",
    "print(adata)\n",
    "\n",
    "# View cell metadata\n",
    "print(adata.obs.head())\n",
    "\n",
    "# View feature (gene/transcript) metadata\n",
    "print(adata.var.head())\n",
    "\n",
    "# View expression matrix shape or a slice\n",
    "print(adata.X.shape)\n",
    "print(adata.X[:5, :5])  # first 5 cells × first 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a3c21-b142-4b98-98fb-3498f1094b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save (optional) ===\n",
    "adata.write_h5ad(\"Intermediate_Files/QC_07232025/PBMC2_iso_AnnData.h5ad\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36272286-bbc3-449d-af05-969f1c192e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "# Load your annotated expression matrix\n",
    "df = pl.read_parquet(\"Parquet_Files/IntermediateFiles/PBMC1_gene_expr_annotated.parquet\")\n",
    "\n",
    "# Extract cell IDs (obs) and expression matrix (X)\n",
    "obs = pl.DataFrame({\"cell_id\": df[\"CellID\"]}).to_pandas().set_index(\"cell_id\")\n",
    "X = df.drop(\"CellID\").to_numpy()\n",
    "\n",
    "# Extract var: the column names *are* the combined IDs\n",
    "combined_ids = df.columns[1:]  # skip \"CellID\"\n",
    "var = pl.DataFrame({\"combined_id\": combined_ids}).to_pandas().set_index(\"combined_id\")\n",
    "\n",
    "# Create AnnData\n",
    "adata = ad.AnnData(X=X, obs=obs, var=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ee7c2-888b-42df-b7d9-2ba4dafcbffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic summary\n",
    "print(adata)\n",
    "\n",
    "# View cell metadata\n",
    "print(adata.obs.head())\n",
    "\n",
    "# View feature (gene/transcript) metadata\n",
    "print(adata.var.head())\n",
    "\n",
    "# View expression matrix shape or a slice\n",
    "print(adata.X.shape)\n",
    "print(adata.X[:5, :5])  # first 5 cells × first 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eab42d8-ab7d-49d6-91a3-f29f9d370ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save (optional) ===\n",
    "adata.write_h5ad(\"Intermediate_Files/QC_07232025/PBMC1_gene_AnnData.h5ad\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeaa2f8-85ea-4c71-944a-2547a814f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "# Load your annotated expression matrix\n",
    "df = pl.read_parquet(\"Parquet_Files/IntermediateFiles/PBMC2_gene_expr_annotated.parquet\")\n",
    "\n",
    "# Extract cell IDs (obs) and expression matrix (X)\n",
    "obs = pl.DataFrame({\"cell_id\": df[\"CellID\"]}).to_pandas().set_index(\"cell_id\")\n",
    "X = df.drop(\"CellID\").to_numpy()\n",
    "\n",
    "# Extract var: the column names *are* the combined IDs\n",
    "combined_ids = df.columns[1:]  # skip \"CellID\"\n",
    "var = pl.DataFrame({\"combined_id\": combined_ids}).to_pandas().set_index(\"combined_id\")\n",
    "\n",
    "# Create AnnData\n",
    "adata = ad.AnnData(X=X, obs=obs, var=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0829b58-2645-4015-930f-7995244367c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic summary\n",
    "print(adata)\n",
    "\n",
    "# View cell metadata\n",
    "print(adata.obs.head())\n",
    "\n",
    "# View feature (gene/transcript) metadata\n",
    "print(adata.var.head())\n",
    "\n",
    "# View expression matrix shape or a slice\n",
    "print(adata.X.shape)\n",
    "print(adata.X[:5, :5])  # first 5 cells × first 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b028356-6a80-4576-903d-07f7d2ee000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save (optional) ===\n",
    "adata.write_h5ad(\"Intermediate_Files/QC_07232025/PBMC2_gene_AnnData.h5ad\", compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
