{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c6f0c-7e6a-49f7-b885-e14d322ce9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "import mudata as mu\n",
    "from scanpy import read_h5ad\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef6bbd-fe1c-4e6b-947e-a36b2380ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scanpy import read_h5ad\n",
    "import os\n",
    "# ---- Load MuData object with cell-type annotations ----\n",
    "output_dir = 'Intermediate_Files/Clustering/'\n",
    "\n",
    "adata_i_filtered = read_h5ad(os.path.join(output_dir, \"PBMC_iso_AutoZI_clustered_celltypes_reannotated_AutoZILatent.h5mu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727caeb2-91ed-4aef-b639-018103df3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check: print the first 10 feature names to confirm expected \"SYMBOL:ENSG:ENST\" formatting.\n",
    "try:\n",
    "    print(\"rna.var_names head:\", adata_i_filtered.var_names[:10].tolist())\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1170696c-95b0-4082-9359-b5886a3e7213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check structure of adata and identify unnecessary parts\n",
    "# Only raw data, cell-type labels, and color assignments for cell-types are needed\n",
    "adata_i_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c68dd5-c098-49f7-87b8-261164a6f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove unneeded parts to slim object to clear up memory\n",
    "\n",
    "# remove unnecessary parts from .obs\n",
    "obs_to_drop = [\n",
    "    '0.04_log_AutoZI', '0.06_log_AutoZI', '0.1_log_AutoZI', '0.14_log_AutoZI', '0.16_log_AutoZI',\n",
    "    '0.2_log_AutoZI', '0.24_log_AutoZI', '0.26_log_AutoZI', '0.3_log_AutoZI',\n",
    "    'TCell_Combined', 'NKCell_Combined', 'Monocyte_Combined',\n",
    "    'BCell_Combined', 'MK_Combined'\n",
    "]\n",
    "adata_i_filtered.obs.drop(columns=[c for c in obs_to_drop if c in adata_i_filtered.obs.columns], inplace=True)\n",
    "\n",
    "# remove unnecessary parts from .uns\n",
    "uns_to_drop = [\n",
    "    '0.04_log_AutoZI', '0.06_log_AutoZI', '0.06_log_AutoZI_colors', '0.14_log_AutoZI',\n",
    "    '0.16_log_AutoZI', '0.1_log_AutoZI', '0.24_log_AutoZI', '0.26_log_AutoZI', '0.2_log_AutoZI',\n",
    "    '0.34_log_AutoZI', '0.36_log_AutoZI', '0.3_log_AutoZI', \n",
    "]\n",
    "for key in uns_to_drop:\n",
    "    if key in adata_i_filtered.uns:\n",
    "        del adata_i_filtered.uns[key]\n",
    "\n",
    "# remove unnecessary parts from .obsm \n",
    "obsm_to_drop = ['X_pca', 'X_umap']\n",
    "for key in obsm_to_drop:\n",
    "    if key in adata_i_filtered.obsm:\n",
    "        del adata_i_filtered.obsm[key]\n",
    "\n",
    "# remove unnecessary layers \n",
    "layers_to_drop = ['denoised', 'log_denoised']\n",
    "for key in layers_to_drop:\n",
    "    if key in adata_i_filtered.layers:\n",
    "        del adata_i_filtered.layers[key]\n",
    "\n",
    "print(adata_i_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d938c5eb-e043-427d-bd8a-c4c7e750c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in unique counts matrices that have undergone filtering from Step 0\n",
    "\n",
    "pbmc1 = pl.read_csv(\n",
    "    \"InitialFiltering/PBMC_patient0_JUNE_16_2025_bambu_quant_PBMC1_combined_uniqueCounts_transcript.filtered_transposed_expression_matrix.txt\",\n",
    "    separator=\"\\t\"\n",
    ")\n",
    "pbmc2 = pl.read_csv(\n",
    "    \"InitialFiltering/PBMC_patient0_JUNE_16_2025_bambu_quant_PBMC2_combined_uniqueCounts_transcript.filtered_transposed_expression_matrix.txt\",\n",
    "    separator=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc13de0e-12bd-4981-b04c-8fb4edf2bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "## ENSG -> symbol (from adata.var_names: Symbol:ENSG:ENST)\n",
    "# Build a frequency map of symbols observed per ENSG using your var_names convention.\n",
    "ensg_to_symbol = defaultdict(Counter)\n",
    "for v in map(str, adata_i_filtered.var_names):\n",
    "    parts = v.split(\":\")\n",
    "    if len(parts) == 3:\n",
    "        sym, ensg, _ = parts\n",
    "        if ensg.startswith(\"ENSG\"):\n",
    "            ensg_to_symbol[ensg][sym] += 1\n",
    "\n",
    "# For each ENSG, pick the most frequent symbol as the “primary” one\n",
    "ensg_primary_symbol = {ensg: cnt.most_common(1)[0][0] for ensg, cnt in ensg_to_symbol.items()}\n",
    "\n",
    "## marker ENSGs (from adata.var_names using your marker symbols) \n",
    "marker_set = {\n",
    "    \"CD3D\",\"CD3E\",\"CD3G\",  # General T cell markers \n",
    "    \"CD8A\",\"CD8B\",\"GATA3\",\"KLRB1\",\"CCL5\",    # Effector CD8 T cell markers\n",
    "    \"CD4\",\"IL2RA\",\"AHR\",\"TNF\",   # Effector CD4 T cell markers\n",
    "    \"CCR7\",\"SELL\",\"TCF7\",   # Memory T cell markers\n",
    "    \"ITGAE\",\"LEF1\",\"CTLA4\",\"IL7R\",\"CD27\",   # Transition T cell markers\n",
    "    \"GZMB\",\"KLRF1\",\"NCAM1\",\"ITGAM\",\"IL2RB\",   # Natural Killer cell markers\n",
    "    \"CD22\",\"CD79A\",\"MS4A1\",\"CD19\",   # B cell markers\n",
    "    \"FCGR2A\",\"CLEC7A\",\"CD33\",\"LILRB4\",   # Monocyte-derived cell markers\n",
    "    \"GP1BA\",\"MPL\",\"ITGA2B\"   # Megakaryocyte markers\n",
    "}\n",
    "\n",
    "## Translate marker symbols into the set of corresponding ENSG IDs present in your dataset.\n",
    "marker_ensg = set()\n",
    "for v in map(str, adata_i_filtered.var_names):\n",
    "    parts = v.split(\":\")\n",
    "    if len(parts) == 3:\n",
    "        sym, ensg, _ = parts\n",
    "        if sym in marker_set and ensg.startswith(\"ENSG\"):\n",
    "            marker_ensg.add(ensg)\n",
    "print(f\"[info] marker ENSGs resolved: {len(marker_ensg)}\")\n",
    "\n",
    "## Find ENSGs that have at least one BambuTx in PBMC1 or PBMC2\n",
    "def ensgs_with_bambu(df: pl.DataFrame) -> set[str]:\n",
    "    out = set()\n",
    "    for c in df.columns[1:]:\n",
    "        if \"|\" not in c:\n",
    "            continue\n",
    "        left, right = c.split(\"|\", 1)\n",
    "        # Bambu transcript on a known gene looks like: BambuTx###|ENSG###########\n",
    "        if left.startswith(\"BambuTx\") and right.startswith(\"ENSG\"):\n",
    "            out.add(right)\n",
    "    return out\n",
    "\n",
    "# Union across PBMC1 and PBMC2 to get all genes with any novel Bambu transcript.\n",
    "ensg_with_novel_1 = ensgs_with_bambu(pbmc1)\n",
    "ensg_with_novel_2 = ensgs_with_bambu(pbmc2)\n",
    "ensg_with_novel_any = ensg_with_novel_1 | ensg_with_novel_2\n",
    "print(f\"[info] ENSGs with ≥1 novel (BambuTx) transcript across PBMC1/2: {len(ensg_with_novel_any)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134a82cd-e146-4188-8467-d7db7e971fa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show shape and first few rows/columns to confirm structure and naming conventions\n",
    "print(\"PBMC1 shape:\", pbmc1.shape)\n",
    "print(\"PBMC2 shape:\", pbmc2.shape)\n",
    "\n",
    "print(\"\\nPBMC1 head:\")\n",
    "print(pbmc1.head())\n",
    "\n",
    "print(\"\\nPBMC1 column names:\")\n",
    "print(pbmc1.columns)\n",
    "\n",
    "print(\"\\nPBMC2 head:\")\n",
    "print(pbmc2.head())\n",
    "\n",
    "print(\"\\nPBMC2 column names:\")\n",
    "print(pbmc2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259f42c-e86b-485f-a9f1-39f6ccde3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build keep lists and rename maps; KEEP RULES:\n",
    "#  1) Keep ALL Bambu (novel) columns.\n",
    "#  2) Keep any column whose right token ENSG is in marker_ensg.\n",
    "#  3) Keep any column whose right token ENSG is in ensg_with_novel_any (ALL transcripts of genes with a novel).\n",
    "def build_keep_and_rename(df: pl.DataFrame):\n",
    "    cols = df.columns\n",
    "    cell_col = cols[0]\n",
    "    keep = [cell_col]\n",
    "    kept_marker, kept_bambu, kept_all_from_novel = [], [], []\n",
    "    rename_map = {}\n",
    "\n",
    "    for c in cols[1:]:\n",
    "        name = str(c)\n",
    "        if \"|\" in name:\n",
    "            left, right = name.split(\"|\", 1)\n",
    "        else:\n",
    "            left, right = name, \"\"\n",
    "\n",
    "        is_bambu = (\"Bambu\" in left) or (\"Bambu\" in right)\n",
    "\n",
    "        # Keep BambuTx, add gene symbol, and restructure combined_id\n",
    "        if is_bambu:\n",
    "            keep.append(c)\n",
    "            kept_bambu.append(c)\n",
    "            if right.startswith(\"ENSG\") and right in ensg_primary_symbol:\n",
    "                rename_map[c] = f\"{left}|{right}|{ensg_primary_symbol[right]}\"\n",
    "            continue\n",
    "\n",
    "        # Keep marker genes and restructure combined_id\n",
    "        if right in marker_ensg:\n",
    "            keep.append(c)\n",
    "            kept_marker.append(c)\n",
    "            if right in ensg_primary_symbol:\n",
    "                rename_map[c] = f\"{left}|{right}|{ensg_primary_symbol[right]}\"\n",
    "            continue\n",
    "\n",
    "        # Keep transcripts woth ≥1 novel (BambuTx) transcript and restructure combined_id\n",
    "        if right in ensg_with_novel_any:\n",
    "            keep.append(c)\n",
    "            kept_all_from_novel.append(c)\n",
    "            if right in ensg_primary_symbol:\n",
    "                rename_map[c] = f\"{left}|{right}|{ensg_primary_symbol[right]}\"\n",
    "\n",
    "    return keep, kept_marker, kept_bambu, kept_all_from_novel, rename_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f15ca-9ad0-48f2-a1e6-44fe7ab6218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keep1, kept_marker1, kept_bambu1, kept_all_from_novel1, rename1 = build_keep_and_rename(pbmc1)\n",
    "keep2, kept_marker2, kept_bambu2, kept_all_from_novel2, rename2 = build_keep_and_rename(pbmc2)\n",
    "\n",
    "print(f\"[info] PBMC1 kept: marker={len(kept_marker1)}  bambu={len(kept_bambu1)}  all_from_novel={len(kept_all_from_novel1)}  total={len(keep1)-1}\")\n",
    "print(f\"[info] PBMC2 kept: marker={len(kept_marker2)}  bambu={len(kept_bambu2)}  all_from_novel={len(kept_all_from_novel2)}  total={len(keep2)-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52901da-8be5-408f-8e0a-e783e670caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply keep-list to each matrix, and rename columns to append the primary SYMBOL\n",
    "pbmc1_filt = pbmc1.select(keep1).rename(rename1) if rename1 else pbmc1.select(keep1)\n",
    "pbmc2_filt = pbmc2.select(keep2).rename(rename2) if rename2 else pbmc2.select(keep2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389eec3f-c2e1-4252-b1df-8765d5fcfe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonize for plotting/concat\n",
    "def harmonize_columns(df_left: pl.DataFrame, df_right: pl.DataFrame):\n",
    "    id_col = df_left.columns[0] # Assume first column is the cell/ID column\n",
    "    left_cols  = set(df_left.columns[1:])\n",
    "    right_cols = set(df_right.columns[1:])\n",
    "    union_cols = sorted(left_cols | right_cols)\n",
    "    def reindex(df: pl.DataFrame) -> pl.DataFrame:\n",
    "        missing = [c for c in union_cols if c not in df.columns]\n",
    "        if missing:\n",
    "            df = df.hstack([pl.Series(c, [0]*df.height) for c in missing])\n",
    "        return df.select([id_col] + union_cols)\n",
    "    return reindex(df_left), reindex(df_right)\n",
    "\n",
    "pbmc1_filt, pbmc2_filt = harmonize_columns(pbmc1_filt, pbmc2_filt)\n",
    "\n",
    "# After this, pbmc1_filt and pbmc2_filt should have identical feature columns (same names, same order), enabling safe concat/compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802a9f03-287e-4318-83bf-8d1bdcc88544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick previews to ensure matching formatting\n",
    "print(\"\\n[preview] PBMC1 first 8 kept marker columns:\")\n",
    "print([c for c in pbmc1_filt.columns[1:] if \"|ENSG\" in c and c.split('|')[1] in marker_ensg][:8])\n",
    "\n",
    "print(\"\\n[preview] PBMC1 first 8 kept from genes-with-novel (non-Bambu):\")\n",
    "print([c for c in pbmc1_filt.columns[1:]\n",
    "       if \"|ENSG\" in c and c.split('|')[1] in ensg_with_novel_any and not c.startswith(\"BambuTx\")][:8])\n",
    "\n",
    "print(\"\\n[preview] PBMC1 first 8 Bambu columns:\")\n",
    "print([c for c in pbmc1_filt.columns[1:] if c.startswith(\"BambuTx\")][:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba951eb-81c5-46b0-ba14-cdbd7f1fa40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "pbmc1_filt.write_csv(\"Intermediate_Files/Unique_Count_Analyses/PBMC1_uniquecounts_filtered_marker_Bambu_withSymbols.txt\", separator=\"\\t\")\n",
    "pbmc2_filt.write_csv(\"Intermediate_Files/Unique_Count_Analyses/PBMC2_uniquecounts_filtered_marker_Bambu_withSymbols.txt\", separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b7a43-a0b0-462a-92f7-18fef894eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up memory from unneeded objects\n",
    "import gc\n",
    "del pbmc1\n",
    "del pbmc2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcace9c8-19ef-4cef-a7d0-ab91eb2a4325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6506eed-8c15-4733-ba85-2e0da332c91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a58a2-18d0-4f57-a30e-a5ac736b4ad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "pbmc1_filt = pl.read_csv(\n",
    "    \"Intermediate_Files/Unique_Count_Analyses/PBMC1_uniquecounts_filtered_marker_Bambu_withSymbols.txt\",\n",
    "    separator=\"\\t\"\n",
    ")\n",
    "\n",
    "pbmc2_filt = pl.read_csv(\n",
    "    \"Intermediate_Files/Unique_Count_Analyses/PBMC2_uniquecounts_filtered_marker_Bambu_withSymbols.txt\",\n",
    "    separator=\"\\t\"\n",
    ")\n",
    "\n",
    "# Check to confirm structure and contents after round-trip save/load.\n",
    "print(pbmc1_filt.head())\n",
    "print(pbmc2_filt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f07f03-8edd-4ab2-9571-8f3fa4987d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs: pbmc1_filt, pbmc2_filt (Polars DataFrames), already harmonized as shown.\n",
    "import re\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Function to identify and extract BambuTx columns (left token \"BambuTx...\" before the first '|')\n",
    "def get_bambu_cols(df: pl.DataFrame) -> list[str]:\n",
    "    cols = []\n",
    "    for c in df.columns[1:]:  # skip first col (CellID)\n",
    "        s = str(c)\n",
    "        left = s.split(\"|\", 1)[0]\n",
    "        if left.startswith(\"BambuTx\"):\n",
    "            cols.append(c)\n",
    "    return cols\n",
    "\n",
    "#Collect BambuTx columns present in either dataset\n",
    "bambu_cols_1 = set(get_bambu_cols(pbmc1_filt))\n",
    "bambu_cols_2 = set(get_bambu_cols(pbmc2_filt))\n",
    "bambu_cols   = sorted(bambu_cols_1 | bambu_cols_2)\n",
    "\n",
    "print(f\"[info] BambuTx columns: PBMC1={len(bambu_cols_1)}  PBMC2={len(bambu_cols_2)}  union={len(bambu_cols)}\")\n",
    "\n",
    "if not bambu_cols:\n",
    "    raise ValueError(\"No BambuTx columns found in the filtered unique-count matrices.\")\n",
    "\n",
    "## Ensure missing Bambu columns exist as zeros\n",
    "def ensure_cols(df: pl.DataFrame, cols: list[str]) -> pl.DataFrame:\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        df = df.hstack([pl.Series(c, [0]*df.height) for c in missing])\n",
    "    return df.select([df.columns[0]] + cols)  # keep CellID + desired columns\n",
    "\n",
    "pbmc1b = ensure_cols(pbmc1_filt, bambu_cols)\n",
    "pbmc2b = ensure_cols(pbmc2_filt, bambu_cols)\n",
    "\n",
    "## Convert the selected Bambu columns to numeric\n",
    "def to_numeric(df: pl.DataFrame, cols: list[str]) -> pl.DataFrame:\n",
    "    return df.with_columns([pl.col(cols).cast(pl.Int64, strict=False)])\n",
    "pbmc1b = to_numeric(pbmc1b, bambu_cols)\n",
    "pbmc2b = to_numeric(pbmc2b, bambu_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032338ae-3f89-457f-b5f2-f26d62d49a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New isoform cellular prevalence from unique-counts (PBMC1 + PBMC2)\n",
    "## Count per-transcript cells (value > 0) in each dataset, then sum across PBMC1+PBMC2\n",
    "def per_transcript_cell_counts(df: pl.DataFrame, cols: list[str]) -> dict[str, int]:\n",
    "    # sum of (col > 0) per column; Polars sums booleans as integers\n",
    "    out = df.select([ (pl.col(c) > 0).sum().alias(c) for c in cols ])\n",
    "    return out.to_dicts()[0]\n",
    "\n",
    "counts1 = per_transcript_cell_counts(pbmc1b, bambu_cols)\n",
    "counts2 = per_transcript_cell_counts(pbmc2b, bambu_cols)\n",
    "\n",
    "## Combine counts (same transcript columns)\n",
    "counts_total = np.array([int(counts1.get(c, 0)) + int(counts2.get(c, 0)) for c in bambu_cols], dtype=int)\n",
    "\n",
    "# Summary stats: Prevalence of novel isoforms across cells.\n",
    "n_transcripts = counts_total.size\n",
    "median_cells  = int(np.median(counts_total))\n",
    "min_cells     = int(counts_total.min())\n",
    "max_cells     = int(counts_total.max())\n",
    "print(f\"[info] Novel transcripts (BambuTx): {n_transcripts}\")\n",
    "print(f\"[info] Cells per transcript: median={median_cells}, range={min_cells}–{max_cells}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a4e37-2c55-4971-b867-481dc63502f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- All novel isoforms (BambuTx): number of cells expressing each, sorted descending ---\n",
    "\n",
    "# Build display labels (prefer SYMBOL if present, else ENSG/BambuGene)\n",
    "def pretty_label(colname: str) -> str:\n",
    "    parts = str(colname).split(\"|\")\n",
    "    left = parts[0] if parts else colname\n",
    "    if len(parts) >= 3 and parts[2]:\n",
    "        right = parts[2]                   # SYMBOL\n",
    "    elif len(parts) >= 2 and parts[1]:\n",
    "        right = parts[1]                   # ENSG or BambuGene\n",
    "    else:\n",
    "        right = \"\"\n",
    "    return f\"{left} | {right}\" if right else left\n",
    "\n",
    "labels = bambu_cols\n",
    "disp_labels = [pretty_label(c) for c in labels]\n",
    "counts_total = np.array([int(counts1.get(c, 0)) + int(counts2.get(c, 0)) for c in labels], dtype=int)\n",
    "\n",
    "# Table sorted by prevalence (most → least) for easier plotting and inspection.\n",
    "df_all = pd.DataFrame({\n",
    "    \"Transcript\": labels,\n",
    "    \"Display\": disp_labels,\n",
    "    \"CellsExpressing\": counts_total\n",
    "}).sort_values(\"CellsExpressing\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"[info] Novel transcripts (BambuTx): {len(df_all)}\")\n",
    "print(df_all.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cc2140-82e7-4e18-96e5-b9f3b0533db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bar Plot: Plot ALL transcripts (horizontal bar chart), most → least\n",
    "\n",
    "# Auto height so labels are readable; cap fontsize accordingly.\n",
    "rows = len(df_all)\n",
    "fig_h = max(4, min(0.28 * rows, 18))  # scale height; cap to 18 inches\n",
    "plt.figure(figsize=(8, fig_h))\n",
    "ax = sns.barplot(\n",
    "    data=df_all,\n",
    "    x=\"CellsExpressing\",\n",
    "    y=\"Display\",\n",
    "    color=\"#377eb8\",\n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "# Bar-end labels (compact)\n",
    "for p in ax.patches:\n",
    "    w = p.get_width()\n",
    "    y = p.get_y() + p.get_height()/2\n",
    "    ax.text(w + max(5, 0.01*w), y, f\"{int(w):,}\", va=\"center\", ha=\"left\", fontsize=8)\n",
    "\n",
    "ax.set_xlabel(\"Cells Expressing Transcript\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_title(\"Novel Isoforms (BambuTx): Cells Expressing Each (PBMC1+PBMC2)\")\n",
    "\n",
    "# Aesthetics\n",
    "sns.despine(left=True, bottom=True)\n",
    "ax.tick_params(axis='y', labelsize=8)\n",
    "ax.tick_params(axis='x', labelsize=9)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Intermediate_Files/Paper_Figs/uniquecounts_bambu_transcripts_cells_expressed_sorted_all.pdf\",\n",
    "            dpi=600, transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Optional: also save the table\n",
    "df_all.to_csv(\"Intermediate_Files/Unique_Count_Analyses/bambu_transcripts_cells_expressed_sorted_all.tsv\",\n",
    "              sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706716b-f50a-4964-bc86-4f4d561d0096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788661a6-8335-4f6e-9f6d-f000be511a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stacked bar for one gene (CD8A): total counts by cell type ---\n",
    "# --- Stacked bar for CD8A: TOTAL COUNTS by cell type (from counts layer) ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from scipy import sparse\n",
    "\n",
    "adata = adata_i_filtered  # your filtered AnnData\n",
    "gene_symbol_target = \"CD8A\"\n",
    "ensembl_fallbacks = {\"CD8A\": [\"ENSG00000153563\"]}  # add more if you wish\n",
    "\n",
    "# --------------- Utility: get counts matrix ----------------\n",
    "X = adata.layers[\"counts\"] if \"counts\" in adata.layers else adata.X\n",
    "is_sparse = sparse.issparse(X)\n",
    "\n",
    "# --------------- Resolve features that belong to the gene ---------------\n",
    "def _series_ci_equals(s: pd.Series, target: str) -> pd.Series:\n",
    "    return s.astype(str).str.upper() == target.upper()\n",
    "\n",
    "def _series_ci_contains(s: pd.Series, target: str) -> pd.Series:\n",
    "    return s.astype(str).str.upper().str.contains(target.upper(), regex=False)\n",
    "\n",
    "def find_feature_indices_for_gene(adata, gene_symbol: str) -> np.ndarray:\n",
    "    var = adata.var.copy()\n",
    "\n",
    "    # 1) exact match in var_names\n",
    "    exact_idx = np.flatnonzero(pd.Series(adata.var_names).str.upper().values == gene_symbol.upper())\n",
    "    if exact_idx.size > 0:\n",
    "        return exact_idx\n",
    "\n",
    "    # 2) exact match in common gene symbol columns\n",
    "    symbol_cols = [c for c in var.columns if \"symbol\" in c.lower() or \"gene_name\" in c.lower() or c.lower() == \"gene\"]\n",
    "    for col in symbol_cols:\n",
    "        m = _series_ci_equals(var[col], gene_symbol)\n",
    "        if m.any():\n",
    "            return np.flatnonzero(m.values)\n",
    "\n",
    "    # 3) Ensembl fallbacks (if provided)\n",
    "    for ens in ensembl_fallbacks.get(gene_symbol, []):\n",
    "        # try any column that looks like ensembl id\n",
    "        ensg_cols = [c for c in var.columns if \"ensembl\" in c.lower() or c.lower() == \"gene_id\" or \"gene_id\" in c.lower()]\n",
    "        for col in ensg_cols:\n",
    "            m = _series_ci_equals(var[col], ens)\n",
    "            if m.any():\n",
    "                return np.flatnonzero(m.values)\n",
    "\n",
    "    # 4) heuristic substring search (common in isoform-level matrices)\n",
    "    #    e.g., var_names like \"ENSG...|CD8A|ENST...\" or columns with \"CD8A-201\"\n",
    "    #    prefer columns where it appears in a gene_name-like field\n",
    "    for col in symbol_cols:\n",
    "        m = _series_ci_contains(var[col], gene_symbol)\n",
    "        if m.any():\n",
    "            return np.flatnonzero(m.values)\n",
    "\n",
    "    # fallback: search var_names substrings\n",
    "    sub_idx = np.flatnonzero(pd.Series(adata.var_names).str.upper().str.contains(gene_symbol.upper(), regex=False).values)\n",
    "    return sub_idx  # may be empty\n",
    "\n",
    "idxs = find_feature_indices_for_gene(adata, gene_symbol_target)\n",
    "if idxs.size == 0:\n",
    "    candidates = (\n",
    "        pd.DataFrame({\"var_name\": adata.var_names})\n",
    "        .assign(\n",
    "            gene_name=adata.var.get(\"gene_name\", pd.Series([\"\"] * adata.n_vars)).astype(str),\n",
    "            symbol=adata.var.get(\"symbol\", pd.Series([\"\"] * adata.n_vars)).astype(str),\n",
    "        )\n",
    "    )\n",
    "    mask_cand = (\n",
    "        candidates[\"var_name\"].str.upper().str.contains(gene_symbol_target)\n",
    "        | candidates[\"gene_name\"].str.upper().str.contains(gene_symbol_target)\n",
    "        | candidates[\"symbol\"].str.upper().str.contains(gene_symbol_target)\n",
    "    )\n",
    "    hits = candidates.loc[mask_cand].head(25)\n",
    "    raise ValueError(\n",
    "        f\"Could not resolve features for '{gene_symbol_target}'. \"\n",
    "        f\"Top candidates (showing up to 25):\\n{hits}\"\n",
    "    )\n",
    "\n",
    "# Build per-transcript counts\n",
    "# label each matching feature\n",
    "var = adata.var.copy()\n",
    "label_cols = [c for c in [\"transcript_id\", \"tx_id\", \"transcript\", \"isoform_id\",\n",
    "                          \"feature_id\", \"name\", \"id\"] if c in var.columns]\n",
    "def _label_for(j):\n",
    "    # prefer transcript_id if available; else var_name\n",
    "    for c in label_cols:\n",
    "        v = str(var.iloc[j][c])\n",
    "        if v and v != \"None\":\n",
    "            return v\n",
    "    return str(adata.var_names[j])\n",
    "\n",
    "tx_indices = np.asarray(idxs)  # from your finder\n",
    "tx_labels  = [ _label_for(j) for j in tx_indices ]\n",
    "\n",
    "# grab counts for just those transcripts\n",
    "X = adata.layers[\"counts\"] if \"counts\" in adata.layers else adata.X\n",
    "from scipy import sparse\n",
    "is_sparse = sparse.issparse(X)\n",
    "\n",
    "if is_sparse:\n",
    "    sub = X[:, tx_indices].toarray()     # (cells × transcripts)\n",
    "else:\n",
    "    sub = np.asarray(X[:, tx_indices])   # (cells × transcripts)\n",
    "\n",
    "# dataframe with cell types\n",
    "if \"gen_cell_type\" not in adata.obs.columns:\n",
    "    raise KeyError(\"adata.obs['gen_cell_type'] is required for grouping.\")\n",
    "cell_types = adata.obs[\"gen_cell_type\"].astype(str).to_numpy()\n",
    "\n",
    "# aggregate TOTAL counts by (transcript, cell_type)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(sub, columns=tx_labels)\n",
    "df[\"gen_cell_type\"] = cell_types\n",
    "by_tx_ct = df.groupby(\"gen_cell_type\", observed=True).sum(numeric_only=True)  # sums per CT\n",
    "# Now we want rows=transcripts, cols=cell types, so transpose:\n",
    "wide = by_tx_ct.T  # index=transcript, columns=cell types\n",
    "\n",
    "# sort transcripts by total counts (descending)\n",
    "wide[\"__Total__\"] = wide.sum(axis=1)\n",
    "wide = wide.sort_values(\"__Total__\", ascending=False)\n",
    "\n",
    "# (optional) show only top N transcripts\n",
    "TOP_N = 30\n",
    "wide = wide.head(TOP_N)\n",
    "\n",
    "# Colors & column order\n",
    "if 'cell_type_colors' in globals() and isinstance(cell_type_colors, dict):\n",
    "    ct_order = [ct for ct in cell_type_colors if ct in wide.columns]\n",
    "    # add any extra CTs not in the palette at the end\n",
    "    ct_order += [ct for ct in wide.columns if ct not in ct_order and ct != \"__Total__\"]\n",
    "    colors = [cell_type_colors.get(ct, \"#999999\") for ct in ct_order]\n",
    "else:\n",
    "    ct_order = [c for c in wide.columns if c != \"__Total__\"]\n",
    "    colors = None\n",
    "\n",
    "# final matrix for plotting\n",
    "plot_mat = wide[ct_order]\n",
    "totals = wide[\"__Total__\"].to_numpy()\n",
    "tx_names = wide.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef76c2-f9b6-4f14-b9fd-0c34dea3d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stacked bar plot (one per transcript) ---------------\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "\n",
    "rows = plot_mat.shape[0]\n",
    "fig_h = max(4, min(0.35 * rows, 18))\n",
    "fig, ax = plt.subplots(figsize=(10, fig_h))\n",
    "\n",
    "y = np.arange(rows)\n",
    "left = np.zeros(rows, dtype=float)\n",
    "handles = []\n",
    "\n",
    "for i, ct in enumerate(ct_order):\n",
    "    vals = plot_mat[ct].to_numpy()\n",
    "    c = (colors[i] if colors is not None else None)\n",
    "    bar = ax.barh(y, vals, left=left, color=c, edgecolor=\"black\", label=ct)\n",
    "    left = left + vals\n",
    "    if colors is not None:\n",
    "        handles.append(Patch(facecolor=c, edgecolor=\"black\", label=ct))\n",
    "\n",
    "ax.set_yticks(y)\n",
    "ax.set_yticklabels(tx_names)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Total counts\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_title(f\"{gene_symbol_target}: transcript-level total counts by cell type (counts layer)\")\n",
    "\n",
    "# write total at ends\n",
    "for i, t in enumerate(totals):\n",
    "    ax.text(t + max(5, 0.01*t), i, f\"{int(t):,}\", va=\"center\", ha=\"left\", fontsize=8)\n",
    "\n",
    "# legend\n",
    "if colors is not None:\n",
    "    ax.legend(handles=handles, title=\"Cell type\", bbox_to_anchor=(1.01, 1), loc=\"upper left\", frameon=True)\n",
    "else:\n",
    "    ax.legend(title=\"Cell type\", bbox_to_anchor=(1.01, 1), loc=\"upper left\", frameon=True)\n",
    "\n",
    "# clean look\n",
    "for spine in (\"left\", \"right\", \"top\"):\n",
    "    ax.spines[spine].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Intermediate_Files/Paper_Figs/CD8A_transcripts_total_counts_by_celltype_countsLayer.pdf\",\n",
    "            dpi=600, transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63db733-f164-444a-a33e-71cf3db48d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CD8A transcripts: TOTAL UNIQUE COUNTS by cell type (PBMC1+PBMC2)\n",
    "# Cell types are pulled from adata_i_filtered.obs['gen_cell_type']\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "\n",
    "## CONFIG \n",
    "ct_order = [\"TCells\", \"NK Cells\", \"BCells\", \"Monocyte-derived\", \"Megakaryocyte\"]\n",
    "target_symbol = \"CD8A\"\n",
    "\n",
    "def get_colors(order):\n",
    "    if 'cell_type_colors' in globals():\n",
    "        return [cell_type_colors.get(ct, cell_type_colors.get(ct.rstrip('s') + 's', \"#999999\")) for ct in order]\n",
    "    return sns.color_palette(\"tab10\", n_colors=len(order))\n",
    "colors = get_colors(ct_order)\n",
    "\n",
    "## FUNCTIONS\n",
    "def parse_tokens(colname: str):\n",
    "    parts = str(colname).split(\"|\")\n",
    "    left   = parts[0] if len(parts) >= 1 else str(colname)   # ENST... or BambuTx...\n",
    "    ensg   = parts[1] if len(parts) >= 2 else \"\"             # ENSG... or BambuGene...\n",
    "    symbol = parts[2] if len(parts) >= 3 else \"\"             # SYMBOL (preferred)\n",
    "    return left, ensg, symbol\n",
    "\n",
    "def pretty_label(colname: str) -> str:\n",
    "    left, ensg, symbol = parse_tokens(colname)\n",
    "    return f\"{left} | {symbol}\" if symbol else (f\"{left} | {ensg}\" if ensg else left)\n",
    "\n",
    "def select_cols_cd8a(df: pl.DataFrame) -> list[str]:\n",
    "    keep = []\n",
    "    for c in df.columns[1:]:  # skip CellID\n",
    "        _, _, sym = parse_tokens(c)\n",
    "        if sym == target_symbol:\n",
    "            keep.append(c)\n",
    "    return keep\n",
    "\n",
    "def ensure_cols(df: pl.DataFrame, cols: list[str]) -> pl.DataFrame:\n",
    "    id_col = df.columns[0]\n",
    "    df = df.with_columns(pl.col(id_col).cast(pl.Utf8))\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        df = df.hstack([pl.Series(name=c, values=pl.repeat(0, df.height, dtype=pl.Int64)) for c in missing])\n",
    "    return df.select([id_col] + cols)\n",
    "\n",
    "# CELL-TYPE TABLE FROM AnnData\n",
    "# Pull gen_cell_type from adata_i_filtered to a small Polars table for joining\n",
    "adata_i_filtered.obs.index = adata_i_filtered.obs.index.astype(str)\n",
    "obs_ct = adata_i_filtered.obs[\"gen_cell_type\"]\n",
    "ct_table = pl.DataFrame({\n",
    "    \"CellID\": obs_ct.index.to_series().astype(str).tolist(),\n",
    "    \"cell_type\": obs_ct.values.tolist()\n",
    "})\n",
    "\n",
    "# Expect pbmc1_filt / pbmc2_filt in memory (first col = CellID, other cols = unique-counts per transcript)\n",
    "cols1 = select_cols_cd8a(pbmc1_filt)\n",
    "cols2 = select_cols_cd8a(pbmc2_filt)\n",
    "target_cols = sorted(set(cols1) | set(cols2))\n",
    "if not target_cols:\n",
    "    sample_hits = [c for c in pbmc1_filt.columns[1:] if \"CD8\" in str(c)][:20]\n",
    "    print(\"[debug] No CD8A transcripts found. Example CD8-like columns:\", sample_hits)\n",
    "    raise ValueError(\"No transcripts with SYMBOL 'CD8A' found. Expect columns like 'ENST...|ENSG...|CD8A'.\")\n",
    "\n",
    "pbmc1_sel = ensure_cols(pbmc1_filt, target_cols)\n",
    "pbmc2_sel = ensure_cols(pbmc2_filt, target_cols)\n",
    "\n",
    "def attach_celltype(df: pl.DataFrame, ct_table: pl.DataFrame) -> pl.DataFrame:\n",
    "    id_col = df.columns[0]\n",
    "    return (\n",
    "        df.rename({id_col: \"CellID\"}).with_columns(pl.col(\"CellID\").cast(pl.Utf8))\n",
    "          .join(ct_table, on=\"CellID\", how=\"left\")\n",
    "          .filter(pl.col(\"cell_type\").is_not_null())\n",
    "    )\n",
    "\n",
    "pbmc1c = attach_celltype(pbmc1_sel, ct_table)\n",
    "pbmc2c = attach_celltype(pbmc2_sel, ct_table)\n",
    "\n",
    "def per_tx_ct_sum(df: pl.DataFrame, cols: list[str]) -> pl.DataFrame:\n",
    "    \"\"\"Sum UNIQUE COUNTS (not presence) per (Transcript, cell_type).\"\"\"\n",
    "    long = df.unpivot(\n",
    "        index=[\"CellID\", \"cell_type\"],\n",
    "        on=cols,\n",
    "        variable_name=\"Transcript\",\n",
    "        value_name=\"val\"\n",
    "    )\n",
    "    return (\n",
    "        long\n",
    "        .group_by([\"Transcript\", \"cell_type\"])\n",
    "        .agg(pl.col(\"val\").sum().alias(\"total_unique_counts\"))\n",
    "    )\n",
    "\n",
    "sum1 = per_tx_ct_sum(pbmc1c, target_cols)\n",
    "sum2 = per_tx_ct_sum(pbmc2c, target_cols)\n",
    "sum_all = (\n",
    "    pl.concat([sum1, sum2])\n",
    "    .group_by([\"Transcript\", \"cell_type\"])\n",
    "    .agg(pl.col(\"total_unique_counts\").sum().alias(\"total_unique_counts\"))\n",
    ")\n",
    "\n",
    "# Pivot -> rows=Transcript, cols=cell_type (TOTAL UNIQUE COUNTS)\n",
    "wide = (\n",
    "    sum_all\n",
    "    .pivot(index=\"Transcript\", columns=\"cell_type\", values=\"total_unique_counts\")\n",
    "    .fill_null(0)\n",
    ")\n",
    "# Ensure all ct columns present & ordered\n",
    "for ct in ct_order:\n",
    "    if ct not in wide.columns:\n",
    "        wide = wide.with_columns(pl.lit(0).alias(ct))\n",
    "wide = wide.select([\"Transcript\"] + ct_order)\n",
    "\n",
    "# To pandas for labeling / sorting\n",
    "wide_pd = wide.to_pandas().set_index(\"Transcript\")\n",
    "wide_pd[\"Display\"] = [pretty_label(t) for t in wide_pd.index]\n",
    "wide_pd[\"Total\"] = wide_pd[ct_order].sum(axis=1)\n",
    "wide_pd = wide_pd.sort_values(\"Total\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf084ca9-e88a-4bbe-ab9e-d03b4ce549b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bar plot: stacked unique counts per transcript by cell type\n",
    "rows = len(wide_pd)\n",
    "fig_h = max(4, min(0.35 * rows, 18))\n",
    "fig, ax = plt.subplots(figsize=(10, fig_h))\n",
    "\n",
    "y = np.arange(rows, dtype=float)\n",
    "left = np.zeros(rows, dtype=float)\n",
    "\n",
    "for color, ct in zip(colors, ct_order):\n",
    "    vals = wide_pd[ct].to_numpy()\n",
    "    ax.barh(y, vals, left=left, color=color, edgecolor=\"black\", label=ct)\n",
    "    left += vals\n",
    "\n",
    "ax.set_yticks(y)\n",
    "ax.set_yticklabels(wide_pd[\"Display\"].values)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Total unique counts\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_title(\"CD8A transcripts: total unique counts by cell type (PBMC1 + PBMC2)\")\n",
    "\n",
    "# total labels at bar ends\n",
    "for i, total in enumerate(wide_pd[\"Total\"].to_numpy()):\n",
    "    ax.text(total + max(5, 0.01*total), i, f\"{int(total):,}\", va=\"center\", ha=\"left\", fontsize=8)\n",
    "\n",
    "legend_handles = [Patch(facecolor=col, edgecolor=\"black\", label=ct) for col, ct in zip(colors, ct_order)]\n",
    "ax.legend(handles=legend_handles, title=\"Cell type\", bbox_to_anchor=(1.01, 1), loc=\"upper left\", frameon=True)\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Intermediate_Files/Unique_Count_Analyses/CD8A_uniquecounts_transcripts_stacked_counts.pdf\",\n",
    "            dpi=600, transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Also export the numeric table of counts\n",
    "out_counts = wide_pd.loc[:, [\"Display\"] + ct_order + [\"Total\"]].reset_index(drop=False).rename(columns={\"index\": \"Transcript\"})\n",
    "out_counts.to_csv(\n",
    "    \"Intermediate_Files/Unique_Count_Analyses/CD8A_uniquecounts_transcripts_counts_table.tsv\",\n",
    "    sep=\"\\t\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c7460-4dea-4870-9b0f-4f859f19016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulk-by-cell-type bar charts of UNIQUE COUNTS per transcript, split by gene \n",
    "# One PDF per gene (all its transcripts in one panel), plus a combined multi-page PDF.\n",
    "\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "## CONFIG / UTILS \n",
    "OUT_DIR_PER_GENE = \"Intermediate_Files/Unique_Count_Analyses/plots/bulk_by_celltype_per_gene\"\n",
    "OUT_COMBINED_PDF = \"Intermediate_Files/Unique_Count_Analyses/plots/bulk_by_celltype_all_genes.pdf\"\n",
    "os.makedirs(OUT_DIR_PER_GENE, exist_ok=True)\n",
    "\n",
    "# Safe filename\n",
    "def safe_name(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = re.sub(r\"[^\\w\\-(). ]+\", \"_\", s)\n",
    "    s = re.sub(r\"\\s+\", \"_\", s).strip(\"_\")\n",
    "    return s[:200]  # avoid super long names\n",
    "\n",
    "# Parse tokens from column name \"LEFT|GENEID|SYMBOL?\" (handles Bambu/ENST)\n",
    "def parse_tokens(colname: str):\n",
    "    parts = str(colname).split(\"|\")\n",
    "    left = parts[0] if parts else colname                     # transcript token (BambuTx### or ENST###)\n",
    "    gene_token = parts[1] if len(parts) >= 2 else \"\"          # ENSG##### or BambuGene#####\n",
    "    symbol = parts[2] if len(parts) >= 3 and parts[2] else \"\" # preferred display if present\n",
    "    return left, gene_token, symbol\n",
    "\n",
    "def gene_display(colname: str) -> str:\n",
    "    left, gene_token, symbol = parse_tokens(colname)\n",
    "    if symbol:\n",
    "        return f\"{symbol} ({gene_token})\"\n",
    "    return gene_token if gene_token else left  # fallback\n",
    "\n",
    "def tx_display(colname: str) -> str:\n",
    "    left, gene_token, symbol = parse_tokens(colname)\n",
    "    # Keep concise, but add symbol if helpful\n",
    "    return left if not symbol else f\"{left}\\n{symbol}\"\n",
    "\n",
    "## PREP DATA\n",
    "# 1) Identify all transcript columns (skip the first 'CellID' column)\n",
    "def transcript_columns(df: pl.DataFrame) -> list[str]:\n",
    "    return [c for c in df.columns[1:]]  # you've already filtered these matrices\n",
    "\n",
    "# Ensure both matrices share the same columns (fill missing with 0)\n",
    "def ensure_cols(df: pl.DataFrame, cols: list[str]) -> pl.DataFrame:\n",
    "    id_col = df.columns[0]\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        df = df.hstack([pl.Series(c, [0]*df.height) for c in missing])\n",
    "    return df.select([id_col] + cols)\n",
    "\n",
    "cols1 = transcript_columns(pbmc1_filt)\n",
    "cols2 = transcript_columns(pbmc2_filt)\n",
    "all_cols = sorted(set(cols1) | set(cols2))\n",
    "pbmc1b = ensure_cols(pbmc1_filt, all_cols)\n",
    "pbmc2b = ensure_cols(pbmc2_filt, all_cols)\n",
    "\n",
    "# 2) Attach cell type to each cell row from adata_i_filtered\n",
    "celltype_map = adata_i_filtered.obs[\"gen_cell_type\"].astype(str).to_dict()\n",
    "\n",
    "def attach_celltype(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    df = df.rename({df.columns[0]: \"CellID\"})\n",
    "    keys = list(celltype_map.keys())\n",
    "    vals = [celltype_map.get(k, None) for k in keys]\n",
    "    ct_df = pl.DataFrame({\"CellID\": keys, \"cell_type\": vals})\n",
    "    return df.join(ct_df, on=\"CellID\", how=\"left\").filter(pl.col(\"cell_type\").is_not_null())\n",
    "\n",
    "pbmc1c = attach_celltype(pbmc1b)\n",
    "pbmc2c = attach_celltype(pbmc2b)\n",
    "\n",
    "# 3) Sum UNIQUE COUNTS per transcript × cell type (PBMC1 + PBMC2)\n",
    "def per_tx_ct_unique_counts(df: pl.DataFrame, cols: list[str]) -> pl.DataFrame:\n",
    "    long = df.unpivot(\n",
    "        index=[\"CellID\", \"cell_type\"],\n",
    "        on=cols,\n",
    "        variable_name=\"Transcript\",\n",
    "        value_name=\"uc\"   # per-cell unique counts\n",
    "    )\n",
    "    return (\n",
    "        long\n",
    "        .group_by([\"Transcript\", \"cell_type\"])\n",
    "        .agg(pl.col(\"uc\").sum().alias(\"unique_counts\"))\n",
    "    )\n",
    "\n",
    "counts1 = per_tx_ct_unique_counts(pbmc1c, all_cols)\n",
    "counts2 = per_tx_ct_unique_counts(pbmc2c, all_cols)\n",
    "counts_all = (\n",
    "    pl.concat([counts1, counts2])\n",
    "    .group_by([\"Transcript\", \"cell_type\"])\n",
    "    .agg(pl.col(\"unique_counts\").sum().alias(\"unique_counts\"))\n",
    ")\n",
    "\n",
    "df_counts = counts_all.to_pandas()\n",
    "\n",
    "# Keep your preferred cell-type order/colors if defined\n",
    "if 'cell_type_order' in globals():\n",
    "    ct_order = [ct for ct in cell_type_order if ct in set(df_counts[\"cell_type\"])]\n",
    "else:\n",
    "    ct_order = sorted(df_counts[\"cell_type\"].unique())\n",
    "\n",
    "## Cell-type order\n",
    "# Force your desired order (do NOT filter by what’s present)\n",
    "ct_order = [\"TCells\", \"NK Cells\", \"BCells\", \"Monocyte-derived\", \"Megakaryocyte\"]\n",
    "\n",
    "# Colors for that order\n",
    "if 'cell_type_colors' in globals():\n",
    "    palette = {ct: cell_type_colors.get(ct, \"#999999\") for ct in ct_order}\n",
    "else:\n",
    "    pal = sns.color_palette(\"tab10\", n_colors=len(ct_order))\n",
    "    palette = {ct: pal[i] for i, ct in enumerate(ct_order)}\n",
    "\n",
    "# Map Transcript -> Gene group\n",
    "tx_to_gene = {t: gene_display(t) for t in all_cols}\n",
    "df_counts[\"Gene\"] = df_counts[\"Transcript\"].map(tx_to_gene)\n",
    "df_counts[\"TranscriptLabel\"] = df_counts[\"Transcript\"].map(tx_display)\n",
    "\n",
    "# Total per gene (no longer used for ordering; keep if you still want the stats)\n",
    "gene_totals = (\n",
    "    df_counts.groupby(\"Gene\")[\"unique_counts\"]\n",
    "             .sum()\n",
    ")\n",
    "\n",
    "# --- Robust alphabetical ordering by preferred gene symbol ---\n",
    "# Sort by:\n",
    "#   1) non-Bambu before BambuGene (optional: keep if you prefer this behavior)\n",
    "#   2) normalized, case-insensitive \"symbol\" (text before the '(' )\n",
    "#   3) natural sort for any digits\n",
    "import unicodedata\n",
    "\n",
    "def _normalize_ascii(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = s.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    return s.strip().lower()\n",
    "\n",
    "def _natural_parts(s: str):\n",
    "    # Split into text and integer chunks for natural ordering (e.g., gene2 < gene10)\n",
    "    parts = re.split(r\"(\\d+)\", s)\n",
    "    return [int(p) if p.isdigit() else p for p in parts]\n",
    "\n",
    "def _symbol_for_sort(g: str) -> str:\n",
    "    # If \"SYMBOL (ENSG...)\" use SYMBOL; else use full string\n",
    "    m = re.match(r\"\\s*([^(]+)\\s*\\(\", str(g))\n",
    "    base = m.group(1) if m else str(g)\n",
    "    return _normalize_ascii(base)\n",
    "\n",
    "def _sort_key(g: str):\n",
    "    sym = _symbol_for_sort(g)\n",
    "    parts = _natural_parts(sym)\n",
    "    is_bambu = str(g).lower().startswith(\"bambugene\")\n",
    "    # Put non-Bambu first, then by natural parts, then full normalized name as tiebreaker\n",
    "    return (is_bambu, parts, sym)\n",
    "\n",
    "genes_sorted = sorted(list(gene_totals.index), key=_sort_key)\n",
    "\n",
    "# (optional) quick sanity peek\n",
    "print(\"First 20, sorted:\", genes_sorted[:20])\n",
    "\n",
    "## PLOTTING (PER GENE)\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "saved_pages = []\n",
    "\n",
    "with PdfPages(OUT_COMBINED_PDF) as bigpdf:\n",
    "    for gene in genes_sorted:\n",
    "        sub = df_counts[df_counts[\"Gene\"] == gene].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        # transcript order by descending unique counts\n",
    "        tx_order = (\n",
    "            sub.groupby(\"TranscriptLabel\")[\"unique_counts\"]\n",
    "               .sum().sort_values(ascending=False).index.tolist()\n",
    "        )\n",
    "        if not tx_order:\n",
    "            continue\n",
    "\n",
    "        # --- COMPLETE TO FULL GRID (TranscriptLabel × cell_type) with zeros ---\n",
    "        sub_grid = (\n",
    "            sub.groupby([\"TranscriptLabel\", \"cell_type\"], as_index=False)[\"unique_counts\"]\n",
    "               .sum()\n",
    "        )\n",
    "\n",
    "        # Build full index across ALL requested categories (even if zero)\n",
    "        full_idx = pd.MultiIndex.from_product([tx_order, ct_order],\n",
    "                                              names=[\"TranscriptLabel\", \"cell_type\"])\n",
    "        sub_grid = (\n",
    "            sub_grid.set_index([\"TranscriptLabel\", \"cell_type\"])\n",
    "                    .reindex(full_idx, fill_value=0)\n",
    "                    .reset_index()\n",
    "        )\n",
    "\n",
    "        # Categorical ordering for seaborn\n",
    "        sub_grid[\"TranscriptLabel\"] = pd.Categorical(sub_grid[\"TranscriptLabel\"],\n",
    "                                                     categories=tx_order, ordered=True)\n",
    "        sub_grid[\"cell_type\"] = pd.Categorical(sub_grid[\"cell_type\"],\n",
    "                                               categories=ct_order, ordered=True)\n",
    "\n",
    "        # figure size scales with # transcripts\n",
    "        n_tx = len(tx_order)\n",
    "        fig_w = max(6, min(0.4 * n_tx + 2, 18))\n",
    "        fig_h = 4\n",
    "        fig, ax = plt.subplots(figsize=(fig_w, fig_h))\n",
    "\n",
    "        sns.barplot(\n",
    "            data=sub_grid,\n",
    "            x=\"TranscriptLabel\", y=\"unique_counts\", hue=\"cell_type\",\n",
    "            order=tx_order, hue_order=ct_order,\n",
    "            palette=palette, edgecolor=\"black\",\n",
    "            estimator=sum, errorbar=None, ax=ax  # explicit identity-like behavior\n",
    "        )\n",
    "\n",
    "        ax.set_xlabel(\"Transcripts\")\n",
    "        ax.set_ylabel(\"Unique Counts (sum over cells)\")\n",
    "        ax.set_title(gene)\n",
    "\n",
    "        # Rotate + right-align x labels\n",
    "        for lbl in ax.get_xticklabels():\n",
    "            lbl.set_rotation(45)\n",
    "            lbl.set_horizontalalignment(\"right\")\n",
    "\n",
    "        sns.despine(ax=ax, top=True, right=True)\n",
    "        ax.legend(title=\"Cell type\", bbox_to_anchor=(1.01, 1), loc=\"upper left\", frameon=True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save individual page (vector) and append to combined\n",
    "        out_path = os.path.join(OUT_DIR_PER_GENE, f\"{safe_name(gene)}.pdf\")\n",
    "        fig.savefig(out_path, dpi=600, transparent=True, bbox_inches=\"tight\")\n",
    "        saved_pages.append(out_path)\n",
    "        bigpdf.savefig(fig, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "print(f\"[info] Wrote {len(saved_pages)} per-gene PDFs to {OUT_DIR_PER_GENE}\")\n",
    "print(f\"[info] Combined multi-page PDF: {OUT_COMBINED_PDF}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694faf52-88a8-48d2-8cf8-05f9e2ae948a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Bulk-by-cell-type bar charts of RAW COUNTS per transcript, split by gene\n",
    "# One PDF per gene (all its transcripts in one panel), plus a combined multi-page PDF.\n",
    "\n",
    "import os, re, unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy import sparse\n",
    "import polars as pl\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "## CONFIG / UTILS\n",
    "\n",
    "OUT_DIR_PER_GENE = \"Intermediate_Files/Unique_Count_Analyses/plots/bulk_by_celltype_per_gene_RAWCOUNTS\"\n",
    "OUT_COMBINED_PDF = \"Intermediate_Files/Unique_Count_Analyses/plots/bulk_by_celltype_all_genes_RAWCOUNTS.pdf\"\n",
    "os.makedirs(OUT_DIR_PER_GENE, exist_ok=True)\n",
    "\n",
    "SCALE_PER = None  # keep None for raw totals\n",
    "\n",
    "def safe_name(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = re.sub(r\"[^\\w\\-(). ]+\", \"_\", s)\n",
    "    s = re.sub(r\"\\s+\", \"_\", s).strip(\"_\")\n",
    "    return s[:200]\n",
    "\n",
    "ct_order = [\"TCells\", \"NK Cells\", \"BCells\", \"Monocyte-derived\", \"Megakaryocyte\"]\n",
    "if 'cell_type_colors' in globals():\n",
    "    palette = {ct: cell_type_colors.get(ct, \"#999999\") for ct in ct_order}\n",
    "else:\n",
    "    pal = sns.color_palette(\"tab10\", n_colors=len(ct_order))\n",
    "    palette = {ct: pal[i] for i, ct in enumerate(ct_order)}\n",
    "\n",
    "## MARKER & NOVEL GENE SETS\n",
    "\n",
    "# ENSG -> symbol map\n",
    "ensg_to_symbol = defaultdict(Counter)\n",
    "for v in map(str, adata_i_filtered.var_names):\n",
    "    parts = v.split(\":\")\n",
    "    if len(parts) == 3:\n",
    "        sym, ensg, _ = parts\n",
    "        if ensg.startswith(\"ENSG\"):\n",
    "            ensg_to_symbol[ensg][sym] += 1\n",
    "ensg_primary_symbol = {ensg: cnt.most_common(1)[0][0] for ensg, cnt in ensg_to_symbol.items()}\n",
    "\n",
    "# marker symbols\n",
    "marker_set = {\n",
    "    \"CD3D\",\"CD3E\",\"CD3G\", # T cell markers\n",
    "    \"CD8A\",\"CD8B\",\"GATA3\",\"KLRB1\",\"CCL5\",   # CD8 Effector T cell markers\n",
    "    \"CD4\",\"IL2RA\",\"AHR\",\"TNF\",   #CD4 Effector T cell markers\n",
    "    \"CCR7\",\"SELL\",\"TCF7\",    # Memory T cell markers\n",
    "    \"ITGAE\",\"LEF1\",\"CTLA4\",\"IL7R\",\"CD27\",   # Transition T cell markers\n",
    "    \"GZMB\",\"KLRF1\",\"NCAM1\",\"ITGAM\",\"IL2RB\",   # NK Cell markers\n",
    "    \"CD22\",\"CD79A\",\"MS4A1\",\"CD19\",     # B cell markers\n",
    "    \"FCGR2A\",\"CLEC7A\",\"CD33\",\"LILRB4\",   # Monocyte-derived cell markers\n",
    "    \"GP1BA\",\"MPL\",\"ITGA2B\"    # Megakaryocyte markers\n",
    "}\n",
    "marker_ensg = set()\n",
    "for v in map(str, adata_i_filtered.var_names):\n",
    "    parts = v.split(\":\")\n",
    "    if len(parts) == 3:\n",
    "        sym, ensg, _ = parts\n",
    "        if sym in marker_set and ensg.startswith(\"ENSG\"):\n",
    "            marker_ensg.add(ensg)\n",
    "print(f\"[info] marker ENSGs resolved: {len(marker_ensg)}\")\n",
    "\n",
    "# find ENSGs with ≥1 novel (BambuTx) transcript\n",
    "def ensgs_with_bambu(df: pl.DataFrame) -> set[str]:\n",
    "    out = set()\n",
    "    for c in df.columns[1:]:\n",
    "        if \"|\" not in c:\n",
    "            continue\n",
    "        left, right = c.split(\"|\", 1)\n",
    "        if left.startswith(\"BambuTx\") and right.startswith(\"ENSG\"):\n",
    "            out.add(right)\n",
    "    return out\n",
    "\n",
    "ensg_with_novel_any = ensgs_with_bambu(pbmc1) | ensgs_with_bambu(pbmc2)\n",
    "print(f\"[info] ENSGs with ≥1 novel transcript: {len(ensg_with_novel_any)}\")\n",
    "\n",
    "keep_ensgs = marker_ensg | ensg_with_novel_any\n",
    "\n",
    "## DATA PREP\n",
    "\n",
    "adata = adata_i_filtered\n",
    "X = adata.layers[\"counts\"] if \"counts\" in adata.layers else adata.X\n",
    "X = X.tocsr() if sparse.issparse(X) else np.asarray(X)\n",
    "\n",
    "ct_series = adata.obs[\"gen_cell_type\"].astype(str)\n",
    "ct_codes = pd.Categorical(ct_series, categories=ct_order, ordered=True).codes\n",
    "valid = ct_codes >= 0\n",
    "n_cells, n_vars, n_ct = adata.n_obs, adata.n_vars, len(ct_order)\n",
    "\n",
    "rows = np.flatnonzero(valid)\n",
    "cols = ct_codes[valid]\n",
    "data = np.ones(rows.shape[0], dtype=np.int8)\n",
    "G = sparse.csr_matrix((data, (rows, cols)), shape=(n_cells, n_ct))\n",
    "\n",
    "if sparse.issparse(X):\n",
    "    X_csr = X.tocsr()\n",
    "    counts_fc = (G.T @ X_csr).T.toarray()\n",
    "else:\n",
    "    counts_fc = X.T @ G.toarray()\n",
    "\n",
    "var = adata.var.copy()\n",
    "var_names = pd.Index(adata.var_names).astype(str)\n",
    "\n",
    "# gene_id (ENSG)\n",
    "if \"gene_id\" in var.columns:\n",
    "    gene_id = var[\"gene_id\"].astype(str).values\n",
    "elif \"ensembl_gene_id\" in var.columns:\n",
    "    gene_id = var[\"ensembl_gene_id\"].astype(str).values\n",
    "else:\n",
    "    def _gene_from_varname(v):\n",
    "        p = str(v).split(\":\")\n",
    "        return p[1] if len(p) >= 2 else v\n",
    "    gene_id = np.array([_gene_from_varname(v) for v in var_names], dtype=object)\n",
    "\n",
    "# gene_symbol\n",
    "if \"gene_name\" in var.columns:\n",
    "    gene_symbol = var[\"gene_name\"].astype(str).values\n",
    "elif \"symbol\" in var.columns:\n",
    "    gene_symbol = var[\"symbol\"].astype(str).values\n",
    "else:\n",
    "    def _sym_from_varname(v):\n",
    "        p = str(v).split(\":\")\n",
    "        return p[0] if len(p) >= 1 else \"\"\n",
    "    gene_symbol = np.array([_sym_from_varname(v) for v in var_names], dtype=object)\n",
    "\n",
    "# transcript label\n",
    "label_cols = [c for c in [\"transcript_id\",\"tx_id\",\"transcript\",\"isoform_id\",\"feature_id\",\"name\",\"id\"] if c in var.columns]\n",
    "def _tx_label(i):\n",
    "    for c in label_cols:\n",
    "        v = str(var.iloc[i][c])\n",
    "        if v and v != \"None\": return v\n",
    "    return str(var_names[i])\n",
    "tx_label = np.array([_tx_label(i) for i in range(n_vars)], dtype=object)\n",
    "\n",
    "tx_label_display = np.where(gene_symbol != \"\",\n",
    "                            [f\"{tx_label[i]}\\n{gene_symbol[i]}\" for i in range(n_vars)],\n",
    "                            tx_label)\n",
    "\n",
    "gene_display = np.where(gene_symbol != \"\",\n",
    "                        [f\"{gene_symbol[i]} ({gene_id[i]})\" if gene_id[i] else gene_symbol[i] for i in range(n_vars)],\n",
    "                        gene_id)\n",
    "\n",
    "counts_df = pd.DataFrame(counts_fc, columns=ct_order)\n",
    "counts_df.insert(0, \"TranscriptLabel\", tx_label_display.tolist())\n",
    "counts_df.insert(1, \"Gene\", gene_display.tolist())\n",
    "counts_df.insert(2, \"ENSG\", gene_id.tolist())\n",
    "\n",
    "df_counts = counts_df.melt(\n",
    "    id_vars=[\"TranscriptLabel\",\"Gene\",\"ENSG\"],\n",
    "    var_name=\"cell_type\",\n",
    "    value_name=\"raw_counts\"\n",
    ")\n",
    "\n",
    "# filter to only marker or novel ENSGs\n",
    "df_counts = df_counts[df_counts[\"ENSG\"].isin(keep_ensgs)]\n",
    "\n",
    "## SORTING\n",
    "\n",
    "def _normalize_ascii(s: str) -> str:\n",
    "    return unicodedata.normalize(\"NFKD\", s).encode(\"ascii\",\"ignore\").decode(\"ascii\").strip().lower()\n",
    "def _nat_parts(s: str):\n",
    "    parts = re.split(r\"(\\d+)\", s)\n",
    "    return [int(p) if p.isdigit() else p for p in parts]\n",
    "def _sym_for_sort(g: str) -> str:\n",
    "    m = re.match(r\"\\s*([^(]+)\\s*\\(\", str(g))\n",
    "    return _normalize_ascii(m.group(1) if m else g)\n",
    "def _sort_key(g: str):\n",
    "    sym = _sym_for_sort(g)\n",
    "    return (str(g).lower().startswith(\"bambugene\"), _nat_parts(sym), sym)\n",
    "\n",
    "genes_sorted = sorted(df_counts[\"Gene\"].dropna().unique().tolist(), key=_sort_key)\n",
    "\n",
    "## PLOTTING\n",
    "\n",
    "saved_pages = []\n",
    "ylab = \"Total counts\" if SCALE_PER is None else f\"Counts per {SCALE_PER:,} cells\"\n",
    "\n",
    "with PdfPages(OUT_COMBINED_PDF) as bigpdf:\n",
    "    for gene in genes_sorted:\n",
    "        sub = df_counts[df_counts[\"Gene\"] == gene]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        txs = sorted(sub[\"TranscriptLabel\"].unique().tolist())\n",
    "        full_idx = pd.MultiIndex.from_product([txs, ct_order], names=[\"TranscriptLabel\",\"cell_type\"])\n",
    "        sub_grid = (sub.groupby([\"TranscriptLabel\",\"cell_type\"], observed=True)[\"raw_counts\"]\n",
    "                        .sum()\n",
    "                        .reindex(full_idx, fill_value=0)\n",
    "                        .reset_index())\n",
    "\n",
    "        tx_order = (sub_grid.groupby(\"TranscriptLabel\", observed=True)[\"raw_counts\"]\n",
    "                               .sum().sort_values(ascending=False).index.tolist())\n",
    "\n",
    "        sub_grid[\"TranscriptLabel\"] = pd.Categorical(sub_grid[\"TranscriptLabel\"], categories=tx_order, ordered=True)\n",
    "        sub_grid[\"cell_type\"] = pd.Categorical(sub_grid[\"cell_type\"], categories=ct_order, ordered=True)\n",
    "\n",
    "        n_tx = len(tx_order)\n",
    "        fig_w = max(6, min(0.4 * n_tx + 2, 18))\n",
    "        fig_h = max(4, min(0.28 * n_tx + 2, 12))\n",
    "        fig, ax = plt.subplots(figsize=(fig_w, fig_h), constrained_layout=True)\n",
    "\n",
    "        bottoms = np.zeros(len(tx_order), dtype=float)\n",
    "        for ct in ct_order:\n",
    "            vals = sub_grid.loc[sub_grid[\"cell_type\"] == ct, [\"TranscriptLabel\",\"raw_counts\"]]\n",
    "            vals = vals.set_index(\"TranscriptLabel\").reindex(tx_order)[\"raw_counts\"].to_numpy()\n",
    "            ax.bar(tx_order, vals, bottom=bottoms,\n",
    "                   color=palette.get(ct, \"#999999\"), edgecolor=\"black\", label=ct)\n",
    "            bottoms += vals\n",
    "\n",
    "        ax.set_xlabel(\"Transcripts\")\n",
    "        ax.set_ylabel(ylab)\n",
    "        ax.set_title(gene)\n",
    "\n",
    "        ax.tick_params(axis=\"x\", labelsize=8, rotation=40)\n",
    "        for lbl in ax.get_xticklabels():\n",
    "            lbl.set_horizontalalignment(\"right\")\n",
    "\n",
    "        sns.despine(ax=ax, top=True, right=True)\n",
    "        ax.legend(title=\"Cell type\", bbox_to_anchor=(1.01, 1), loc=\"upper left\", frameon=True)\n",
    "\n",
    "        out_path = os.path.join(OUT_DIR_PER_GENE, f\"{safe_name(gene)}.pdf\")\n",
    "        fig.savefig(out_path, dpi=600, transparent=True, bbox_inches=\"tight\")\n",
    "        saved_pages.append(out_path)\n",
    "        bigpdf.savefig(fig, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "print(f\"[info] Wrote {len(saved_pages)} per-gene PDFs to {OUT_DIR_PER_GENE}\")\n",
    "print(f\"[info] Combined multi-page PDF: {OUT_COMBINED_PDF}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3674b-b632-4844-8638-5fac2f6a8311",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bulk-by-sub-cell-type bar charts of UNIQUE COUNTS per transcript, split by gene \n",
    "# One PDF per gene (all its transcripts in one panel), plus a combined multi-page PDF.\n",
    "\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "## CONFIG / UTILS\n",
    "OUT_DIR_PER_GENE = \"Intermediate_Files/Unique_Count_Analyses/plots/bulk_by_SUBcelltype_per_gene\"\n",
    "OUT_COMBINED_PDF = \"Intermediate_Files/Unique_Count_Analyses/plots/bulk_by_SUBcelltype_all_genes.pdf\"\n",
    "os.makedirs(OUT_DIR_PER_GENE, exist_ok=True)\n",
    "\n",
    "# Desired sub-cell-type order (exact)\n",
    "sub_ct_order = [\n",
    "    \"Effector CD4 TCells\",\n",
    "    \"Cytotoxic TCells\",\n",
    "    \"Memory TCells\",\n",
    "    \"Effector-Memory Transition TCells\",\n",
    "    \"NK Cells\",\n",
    "    \"B Cells\",\n",
    "    \"Monocyte-derived\",\n",
    "    \"Megakaryocytes\",\n",
    "]\n",
    "\n",
    "def safe_name(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = re.sub(r\"[^\\w\\-(). ]+\", \"_\", s)\n",
    "    s = re.sub(r\"\\s+\", \"_\", s).strip(\"_\")\n",
    "    return s[:200]\n",
    "\n",
    "def parse_tokens(colname: str):\n",
    "    parts = str(colname).split(\"|\")\n",
    "    left = parts[0] if parts else colname\n",
    "    gene_token = parts[1] if len(parts) >= 2 else \"\"\n",
    "    symbol = parts[2] if len(parts) >= 3 and parts[2] else \"\"\n",
    "    return left, gene_token, symbol\n",
    "\n",
    "def gene_display(colname: str) -> str:\n",
    "    left, gene_token, symbol = parse_tokens(colname)\n",
    "    if symbol:\n",
    "        return f\"{symbol} ({gene_token})\"\n",
    "    return gene_token if gene_token else left\n",
    "\n",
    "def tx_display(colname: str) -> str:\n",
    "    left, gene_token, symbol = parse_tokens(colname)\n",
    "    return left if not symbol else f\"{left}\\n{symbol}\"\n",
    "\n",
    "# ============================ PREP DATA ============================\n",
    "\n",
    "def transcript_columns(df: pl.DataFrame) -> list[str]:\n",
    "    return [c for c in df.columns[1:]]\n",
    "\n",
    "def ensure_cols(df: pl.DataFrame, cols: list[str]) -> pl.DataFrame:\n",
    "    id_col = df.columns[0]\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        df = df.hstack([pl.Series(c, [0]*df.height) for c in missing])\n",
    "    return df.select([id_col] + cols)\n",
    "\n",
    "cols1 = transcript_columns(pbmc1_filt)\n",
    "cols2 = transcript_columns(pbmc2_filt)\n",
    "all_cols = sorted(set(cols1) | set(cols2))\n",
    "pbmc1b = ensure_cols(pbmc1_filt, all_cols)\n",
    "pbmc2b = ensure_cols(pbmc2_filt, all_cols)\n",
    "\n",
    "# Attach *sub_cell_type* to each cell row\n",
    "subtype_series = adata_i_filtered.obs[\"sub_cell_type\"].astype(str)\n",
    "subtype_map = subtype_series.to_dict()\n",
    "\n",
    "def attach_subtype(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    df = df.rename({df.columns[0]: \"CellID\"})\n",
    "    keys = list(subtype_map.keys())\n",
    "    vals = [subtype_map.get(k, None) for k in keys]\n",
    "    ct_df = pl.DataFrame({\"CellID\": keys, \"sub_cell_type\": vals})\n",
    "    return df.join(ct_df, on=\"CellID\", how=\"left\").filter(pl.col(\"sub_cell_type\").is_not_null())\n",
    "\n",
    "pbmc1c = attach_subtype(pbmc1b)\n",
    "pbmc2c = attach_subtype(pbmc2b)\n",
    "\n",
    "# Sum UNIQUE COUNTS per transcript × sub-cell-type (PBMC1 + PBMC2)\n",
    "def per_tx_subct_unique_counts(df: pl.DataFrame, cols: list[str]) -> pl.DataFrame:\n",
    "    long = df.unpivot(\n",
    "        index=[\"CellID\", \"sub_cell_type\"],\n",
    "        on=cols,\n",
    "        variable_name=\"Transcript\",\n",
    "        value_name=\"uc\"\n",
    "    )\n",
    "    return (\n",
    "        long\n",
    "        .group_by([\"Transcript\", \"sub_cell_type\"])\n",
    "        .agg(pl.col(\"uc\").sum().alias(\"unique_counts\"))\n",
    "    )\n",
    "\n",
    "counts1 = per_tx_subct_unique_counts(pbmc1c, all_cols)\n",
    "counts2 = per_tx_subct_unique_counts(pbmc2c, all_cols)\n",
    "counts_all = (\n",
    "    pl.concat([counts1, counts2])\n",
    "    .group_by([\"Transcript\", \"sub_cell_type\"])\n",
    "    .agg(pl.col(\"unique_counts\").sum().alias(\"unique_counts\"))\n",
    ")\n",
    "\n",
    "df_counts = counts_all.to_pandas()\n",
    "\n",
    "# Force your exact order and keep all categories (missing ones will be filled with 0 later)\n",
    "ct_order = sub_ct_order[:]\n",
    "\n",
    "# Colors: use sub_cell_type_colors if present; else build one\n",
    "if 'sub_cell_type_colors' in globals():\n",
    "    palette = {ct: sub_cell_type_colors.get(ct, \"#999999\") for ct in ct_order}\n",
    "else:\n",
    "    pal = sns.color_palette(\"tab20\", n_colors=len(ct_order))\n",
    "    palette = {ct: pal[i] for i, ct in enumerate(ct_order)}\n",
    "\n",
    "# Map Transcript -> Gene group\n",
    "tx_to_gene = {t: gene_display(t) for t in all_cols}\n",
    "df_counts[\"Gene\"] = df_counts[\"Transcript\"].map(tx_to_gene)\n",
    "df_counts[\"TranscriptLabel\"] = df_counts[\"Transcript\"].map(tx_display)\n",
    "\n",
    "# --- Robust alphabetical ordering by preferred gene symbol ---\n",
    "def _normalize_ascii(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = s.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    return s.strip().lower()\n",
    "\n",
    "def _natural_parts(s: str):\n",
    "    parts = re.split(r\"(\\d+)\", s)\n",
    "    return [int(p) if p.isdigit() else p for p in parts]\n",
    "\n",
    "def _symbol_for_sort(g: str) -> str:\n",
    "    m = re.match(r\"\\s*([^(]+)\\s*\\(\", str(g))\n",
    "    base = m.group(1) if m else str(g)\n",
    "    return _normalize_ascii(base)\n",
    "\n",
    "def _sort_key(g: str):\n",
    "    sym = _symbol_for_sort(g)\n",
    "    parts = _natural_parts(sym)\n",
    "    is_bambu = str(g).lower().startswith(\"bambugene\")\n",
    "    return (is_bambu, parts, sym)\n",
    "\n",
    "genes_sorted = sorted(df_counts[\"Gene\"].unique(), key=_sort_key)\n",
    "\n",
    "## PLOTTING (PER GENE)\n",
    "\n",
    "saved_pages = []\n",
    "\n",
    "with PdfPages(OUT_COMBINED_PDF) as bigpdf:\n",
    "    for gene in genes_sorted:\n",
    "        sub = df_counts[df_counts[\"Gene\"] == gene].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        # transcript order by descending unique counts\n",
    "        tx_order = (\n",
    "            sub.groupby(\"TranscriptLabel\")[\"unique_counts\"]\n",
    "               .sum().sort_values(ascending=False).index.tolist()\n",
    "        )\n",
    "        if not tx_order:\n",
    "            continue\n",
    "\n",
    "        # complete to full grid (TranscriptLabel × sub_cell_type) with zeros\n",
    "        sub_grid = (\n",
    "            sub.groupby([\"TranscriptLabel\", \"sub_cell_type\"], as_index=False)[\"unique_counts\"]\n",
    "               .sum()\n",
    "        )\n",
    "        full_idx = pd.MultiIndex.from_product([tx_order, ct_order],\n",
    "                                              names=[\"TranscriptLabel\", \"sub_cell_type\"])\n",
    "        sub_grid = (\n",
    "            sub_grid.set_index([\"TranscriptLabel\", \"sub_cell_type\"])\n",
    "                    .reindex(full_idx, fill_value=0)\n",
    "                    .reset_index()\n",
    "        )\n",
    "\n",
    "        sub_grid[\"TranscriptLabel\"] = pd.Categorical(sub_grid[\"TranscriptLabel\"],\n",
    "                                                     categories=tx_order, ordered=True)\n",
    "        sub_grid[\"sub_cell_type\"] = pd.Categorical(sub_grid[\"sub_cell_type\"],\n",
    "                                                   categories=ct_order, ordered=True)\n",
    "\n",
    "        n_tx = len(tx_order)\n",
    "        fig_w = max(6, min(0.4 * n_tx + 2, 18))\n",
    "        fig_h = 4\n",
    "        fig, ax = plt.subplots(figsize=(fig_w, fig_h))\n",
    "\n",
    "        sns.barplot(\n",
    "            data=sub_grid,\n",
    "            x=\"TranscriptLabel\", y=\"unique_counts\", hue=\"sub_cell_type\",\n",
    "            order=tx_order, hue_order=ct_order,\n",
    "            palette=palette, edgecolor=\"black\",\n",
    "            estimator=sum, errorbar=None, ax=ax\n",
    "        )\n",
    "\n",
    "        ax.set_xlabel(\"Transcripts\")\n",
    "        ax.set_ylabel(\"Unique Counts (sum over cells)\")\n",
    "        ax.set_title(gene)\n",
    "\n",
    "        for lbl in ax.get_xticklabels():\n",
    "            lbl.set_rotation(45)\n",
    "            lbl.set_horizontalalignment(\"right\")\n",
    "\n",
    "        sns.despine(ax=ax, top=True, right=True)\n",
    "        ax.legend(title=\"Sub cell type\", bbox_to_anchor=(1.01, 1), loc=\"upper left\", frameon=True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        out_path = os.path.join(OUT_DIR_PER_GENE, f\"{safe_name(gene)}.pdf\")\n",
    "        fig.savefig(out_path, dpi=600, transparent=True, bbox_inches=\"tight\")\n",
    "        saved_pages.append(out_path)\n",
    "        bigpdf.savefig(fig, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "print(f\"[info] Wrote {len(saved_pages)} per-gene PDFs to {OUT_DIR_PER_GENE}\")\n",
    "print(f\"[info] Combined multi-page PDF: {OUT_COMBINED_PDF}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ffdc61-e2ab-425e-b452-b9e878badb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bulk-by-sub-cell-type bar charts of RAW COUNTS per transcript, split by gene (FILTERED)\n",
    "# Uses pbmc1_filt / pbmc2_filt to:\n",
    "#   (1) detect ENSGs with >1 novel BambuTx, and\n",
    "#   (2) backfill ENSG for Bambu-only features in adata.var.\n",
    "# Pages are grouped by ENSG (GeneKey). Titles show SYMBOL (ENSG).\n",
    "# Keeps ONLY: marker ENSGs OR ENSGs with >1 novel (BambuTx). RAW totals (no normalization).\n",
    "\n",
    "import os, re, unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy import sparse\n",
    "import polars as pl\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "## CONFIG / UTILS\n",
    "\n",
    "OUT_DIR_PER_GENE = \"Intermediate_Files/Unique_Count_Analyses/plots/bulk_by_subcelltype_per_gene_RAWCOUNTS\"\n",
    "OUT_COMBINED_PDF = \"Intermediate_Files/Unique_Count_Analyses/plots/bulk_by_subcelltype_all_genes_RAWCOUNTS.pdf\"\n",
    "os.makedirs(OUT_DIR_PER_GENE, exist_ok=True)\n",
    "\n",
    "SCALE_PER = None  # RAW totals\n",
    "\n",
    "def safe_name(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = re.sub(r\"[^\\w\\-(). ]+\", \"_\", s)\n",
    "    s = re.sub(r\"\\s+\", \"_\", s).strip(\"_\")\n",
    "    return s[:200]\n",
    "\n",
    "# ---- Robust token parser: split on both '|' and ':' and detect by prefix ----\n",
    "def split_tokens(name: str):\n",
    "    s = str(name)\n",
    "    s2 = s.replace(\"|\", \":\")\n",
    "    return [p.strip() for p in s2.split(\":\") if p.strip()]\n",
    "\n",
    "def parse_tokens_robust(name: str):\n",
    "    \"\"\"Return (tx_id, ensg, symbol_guess) by scanning tokens.\"\"\"\n",
    "    parts = split_tokens(name)\n",
    "    tx_id = \"\"\n",
    "    ensg  = \"\"\n",
    "    symbol_guess = \"\"\n",
    "    for p in parts:\n",
    "        if not tx_id and (p.startswith(\"BambuTx\") or p.startswith(\"ENST\")):\n",
    "            tx_id = p\n",
    "        if not ensg and p.startswith(\"ENSG\"):\n",
    "            ensg = p\n",
    "    for p in parts:\n",
    "        if p.startswith((\"BambuTx\",\"ENST\",\"ENSG\",\"BambuGene\")):\n",
    "            continue\n",
    "        if 1 <= len(p) <= 20 and \" \" not in p:\n",
    "            symbol_guess = p\n",
    "            break\n",
    "    if not tx_id:\n",
    "        tx_id = parts[0] if parts else str(name)\n",
    "    return tx_id, ensg, symbol_guess\n",
    "\n",
    "def tx_display_from_name(name: str) -> str:\n",
    "    tx, ensg, sym = parse_tokens_robust(name)\n",
    "    return tx if not sym else f\"{tx}\\n{sym}\"\n",
    "\n",
    "def _ensg_core(x):\n",
    "    x = str(x) if x is not None else \"\"\n",
    "    x = x.split(\"|\", 1)[0].strip()  # drop trailing |SYMBOL if any\n",
    "    x = x.split(\".\", 1)[0].strip()  # drop version suffix like .13\n",
    "    return x if x.startswith(\"ENSG\") else \"\"\n",
    "\n",
    "# normalize sub-cell-type (plug aliases if needed)\n",
    "def norm_subct(s: str) -> str:\n",
    "    return str(s).strip()\n",
    "\n",
    "# palette and order for sub-cell-types\n",
    "if 'sub_cell_type_colors' in globals():\n",
    "    subct_order = list(sub_cell_type_colors.keys())\n",
    "    palette = {ct: sub_cell_type_colors.get(ct, \"#999999\") for ct in subct_order}\n",
    "else:\n",
    "    subct_order = sorted(adata_i_filtered.obs[\"sub_cell_type\"].astype(str).unique())\n",
    "    pal = sns.color_palette(\"tab20\", n_colors=len(subct_order))\n",
    "    palette = {ct: pal[i] for i, ct in enumerate(subct_order)}\n",
    "\n",
    "### MARKER & NOVEL GENE SETS\n",
    "\n",
    "# ENSG -> symbol (best-effort) from var_names\n",
    "ensg_to_symbol = defaultdict(Counter)\n",
    "for v in map(str, adata_i_filtered.var_names):\n",
    "    parts = split_tokens(v)\n",
    "    sym = \"\"\n",
    "    ensg = \"\"\n",
    "    for p in parts:\n",
    "        if not ensg and p.startswith(\"ENSG\"): ensg = p\n",
    "        if not sym and not p.startswith((\"ENSG\",\"ENST\",\"BambuTx\",\"BambuGene\")): sym = p\n",
    "    if ensg and sym:\n",
    "        ensg_to_symbol[ensg][sym] += 1\n",
    "ensg_primary_symbol = {e: cnt.most_common(1)[0][0] for e, cnt in ensg_to_symbol.items()}\n",
    "\n",
    "marker_set = {\n",
    "    \"CD3D\",\"CD3E\",\"CD3G\",\n",
    "    \"CD8A\",\"CD8B\",\"GATA3\",\"KLRB1\",\"CCL5\",\n",
    "    \"CD4\",\"IL2RA\",\"AHR\",\"TNF\",\n",
    "    \"CCR7\",\"SELL\",\"TCF7\",\n",
    "    \"ITGAE\",\"LEF1\",\"CTLA4\",\"IL7R\",\"CD27\",\n",
    "    \"GZMB\",\"KLRF1\",\"NCAM1\",\"ITGAM\",\"IL2RB\",\n",
    "    \"CD22\",\"CD79A\",\"MS4A1\",\"CD19\",\n",
    "    \"FCGR2A\",\"CLEC7A\",\"CD33\",\"LILRB4\",\n",
    "    \"GP1BA\",\"MPL\",\"ITGA2B\"\n",
    "}\n",
    "\n",
    "# Marker ENSGs from var_names and var columns\n",
    "marker_ensg = set()\n",
    "for v in map(str, adata_i_filtered.var_names):\n",
    "    parts = split_tokens(v)\n",
    "    sym = \"\"\n",
    "    ensg = \"\"\n",
    "    for p in parts:\n",
    "        if not ensg and p.startswith(\"ENSG\"): ensg = p\n",
    "        if not sym and not p.startswith((\"ENSG\",\"ENST\",\"BambuTx\",\"BambuGene\")): sym = p\n",
    "    if ensg and sym in marker_set:\n",
    "        marker_ensg.add(ensg)\n",
    "if {\"gene_id\",\"gene_name\"}.issubset(adata_i_filtered.var.columns):\n",
    "    var_sub = adata_i_filtered.var[[\"gene_id\",\"gene_name\"]].astype(str)\n",
    "    add_ensg = set(var_sub.loc[var_sub[\"gene_name\"].isin(marker_set), \"gene_id\"])\n",
    "    marker_ensg |= {e for e in add_ensg if str(e).startswith(\"ENSG\")}\n",
    "\n",
    "# Build BambuTx -> ENSG and count novels (>1) from pbmc1_filt & pbmc2_filt\n",
    "def build_bambu_maps_and_counts(*dfs: pl.DataFrame):\n",
    "    tx_to_ensg = {}\n",
    "    ensg_ctr = Counter()\n",
    "    for df in dfs:\n",
    "        for c in df.columns[1:]:\n",
    "            if \"|\" not in c: \n",
    "                continue\n",
    "            left, right = c.split(\"|\", 1)  # left=BambuTx### or ENST..., right='ENSG...|SYMBOL' or 'ENSG...'\n",
    "            if not left.startswith(\"BambuTx\"):\n",
    "                continue\n",
    "            ensg = _ensg_core(right)\n",
    "            if ensg:\n",
    "                tx_to_ensg[left] = ensg\n",
    "                ensg_ctr[ensg] += 1\n",
    "    return tx_to_ensg, ensg_ctr\n",
    "\n",
    "# NOTE: use pbmc1_filt and pbmc2_filt (not pbmc1 / pbmc2)\n",
    "txid_to_ensg, novel_ctr = build_bambu_maps_and_counts(pbmc1_filt, pbmc2_filt)\n",
    "ensg_with_gt1_novel = {e for e, k in novel_ctr.items() if k > 1}\n",
    "\n",
    "keep_ensgs = marker_ensg | ensg_with_gt1_novel\n",
    "print(f\"[info] marker ENSGs: {len(marker_ensg)} | ENSGs with >1 novel: {len(ensg_with_gt1_novel)} | total keep: {len(keep_ensgs)}\")\n",
    "print(f\"[info] example BambuTx→ENSG: {list(txid_to_ensg.items())[:5]}\")\n",
    "\n",
    "### DATA PREP\n",
    "\n",
    "adata = adata_i_filtered\n",
    "X = adata.layers[\"counts\"] if \"counts\" in adata.layers else adata.X\n",
    "X = X.tocsr() if sparse.issparse(X) else np.asarray(X)\n",
    "\n",
    "subct_series = adata.obs[\"sub_cell_type\"].astype(str).map(norm_subct)\n",
    "codes = pd.Categorical(subct_series, categories=subct_order, ordered=True).codes\n",
    "valid = codes >= 0\n",
    "n_cells, n_vars, n_ct = adata.n_obs, adata.n_vars, len(subct_order)\n",
    "\n",
    "rows = np.flatnonzero(valid)\n",
    "cols = codes[valid]\n",
    "data = np.ones(rows.shape[0], dtype=np.int8)\n",
    "G = sparse.csr_matrix((data, (rows, cols)), shape=(n_cells, n_ct))\n",
    "\n",
    "if sparse.issparse(X):\n",
    "    X_csr = X.tocsr()\n",
    "    counts_fc = (G.T @ X_csr).T.toarray()   # (features × sub-CT)\n",
    "else:\n",
    "    counts_fc = X.T @ G.toarray()\n",
    "\n",
    "## LABELS & BACKFILL\n",
    "\n",
    "var = adata.var.copy()\n",
    "var_names = pd.Index(adata.var_names).astype(str)\n",
    "\n",
    "# Robust tokens from var_names\n",
    "tx_ids_from_names = np.array([parse_tokens_robust(v)[0] for v in var_names], dtype=object)\n",
    "ensg_from_names   = np.array([parse_tokens_robust(v)[1] for v in var_names], dtype=object)\n",
    "sym_from_names    = np.array([parse_tokens_robust(v)[2] for v in var_names], dtype=object)\n",
    "\n",
    "# ENSG from var if present; else from names; then backfill from Bambu map; sanitize to core\n",
    "if \"gene_id\" in var.columns:\n",
    "    ensg_arr = var[\"gene_id\"].astype(str).values\n",
    "elif \"ensembl_gene_id\" in var.columns:\n",
    "    ensg_arr = var[\"ensembl_gene_id\"].astype(str).values\n",
    "else:\n",
    "    ensg_arr = ensg_from_names\n",
    "\n",
    "ensg_filled = []\n",
    "for i in range(len(ensg_arr)):\n",
    "    g = _ensg_core(ensg_arr[i])\n",
    "    if g:\n",
    "        ensg_filled.append(g)\n",
    "    else:\n",
    "        # extract BambuTx if embedded (e.g., \"BambuGene123:BambuTx45\")\n",
    "        txid = str(tx_ids_from_names[i])\n",
    "        if \":\" in txid and \"BambuTx\" in txid:\n",
    "            btoks = [p for p in split_tokens(txid) if p.startswith(\"BambuTx\")]\n",
    "            txid_key = btoks[0] if btoks else txid\n",
    "        else:\n",
    "            txid_key = txid\n",
    "        ensg_filled.append(_ensg_core(txid_to_ensg.get(txid_key, \"\")))\n",
    "\n",
    "ensg_filled = np.array(ensg_filled, dtype=object)\n",
    "\n",
    "# symbol for display (prefer var; else robust name parse; else ENSG->primary-symbol map)\n",
    "if \"gene_name\" in var.columns:\n",
    "    gene_symbol = var[\"gene_name\"].astype(str).values\n",
    "elif \"symbol\" in var.columns:\n",
    "    gene_symbol = var[\"symbol\"].astype(str).values\n",
    "else:\n",
    "    gene_symbol = sym_from_names\n",
    "\n",
    "tx_label = np.array([tx_display_from_name(v) for v in var_names], dtype=object)\n",
    "gene_display = []\n",
    "for i in range(len(ensg_filled)):\n",
    "    gid = ensg_filled[i] if isinstance(ensg_filled[i], str) else \"\"\n",
    "    sym_guess = ensg_primary_symbol.get(gid, \"\")\n",
    "    sym = sym_guess or (str(gene_symbol[i]) if gene_symbol is not None else \"\")\n",
    "    gene_display.append(f\"{sym} ({gid})\" if sym and gid else (sym or gid or str(var_names[i])))\n",
    "\n",
    "## LONG TABLE & FILTER\n",
    "\n",
    "counts_df = pd.DataFrame(counts_fc, columns=subct_order)\n",
    "counts_df.insert(0, \"Transcript\", var_names.tolist())\n",
    "counts_df.insert(1, \"TxID\", tx_ids_from_names.tolist())\n",
    "counts_df.insert(2, \"TranscriptLabel\", tx_label.tolist())\n",
    "counts_df.insert(3, \"GeneKey\", ensg_filled.tolist())       # ENSG (backfilled)\n",
    "counts_df.insert(4, \"GeneDisplay\", gene_display)\n",
    "\n",
    "df_counts = counts_df.melt(\n",
    "    id_vars=[\"Transcript\",\"TxID\",\"TranscriptLabel\",\"GeneKey\",\"GeneDisplay\"],\n",
    "    var_name=\"sub_cell_type\",\n",
    "    value_name=\"raw_counts\"\n",
    ")\n",
    "\n",
    "# Effective keep = what you want AND what exists in matrix\n",
    "present_gene_keys = {ek for ek in ensg_filled if isinstance(ek, str) and ek.startswith(\"ENSG\")}\n",
    "keep_ensgs_eff = { _ensg_core(k) for k in keep_ensgs } & present_gene_keys\n",
    "\n",
    "missing_from_matrix = sorted(keep_ensgs - keep_ensgs_eff)\n",
    "if missing_from_matrix:\n",
    "    miss_disp = [f\"{e} ({ensg_primary_symbol.get(e,'?')})\" for e in missing_from_matrix[:20]]\n",
    "    print(f\"[info] {len(missing_from_matrix)} keep ENSGs absent from matrix; first few: {miss_disp}\")\n",
    "\n",
    "before = df_counts[\"GeneKey\"].nunique()\n",
    "df_counts = df_counts[df_counts[\"GeneKey\"].isin(keep_ensgs_eff)].copy()\n",
    "after = df_counts[\"GeneKey\"].nunique()\n",
    "print(f\"[debug] unique GeneKey before filter: {before} | after effective filter: {after} (expect {len(keep_ensgs_eff)})\")\n",
    "\n",
    "## SORTING\n",
    "\n",
    "def _normalize_ascii(s: str) -> str:\n",
    "    s = str(s)\n",
    "    return unicodedata.normalize(\"NFKD\", s).encode(\"ascii\",\"ignore\").decode(\"ascii\").strip().lower()\n",
    "def _nat_parts(s: str):\n",
    "    s = str(s); parts = re.split(r\"(\\d+)\", s)\n",
    "    return [int(p) if p.isdigit() else p for p in parts]\n",
    "def _sym_for_sort(g: str) -> str:\n",
    "    m = re.match(r\"\\s*([^(]+)\\s*\\(\", str(g))\n",
    "    return _normalize_ascii(m.group(1) if m else g)\n",
    "def _sort_key(g: str):\n",
    "    sym = _sym_for_sort(g)\n",
    "    return (str(g).lower().startswith(\"bambugene\"), _nat_parts(sym), sym)\n",
    "\n",
    "ensg_to_display = (df_counts[[\"GeneKey\",\"GeneDisplay\"]]\n",
    "                   .drop_duplicates()\n",
    "                   .set_index(\"GeneKey\")[\"GeneDisplay\"]\n",
    "                   .to_dict())\n",
    "\n",
    "gene_keys_sorted = sorted(keep_ensgs_eff, key=lambda k: _sort_key(ensg_to_display.get(k, k)))\n",
    "print(f\"[debug] pages to write: {len(gene_keys_sorted)} (should be {len(keep_ensgs_eff)})\")\n",
    "\n",
    "## PLOTTING\n",
    "\n",
    "saved_pages = []\n",
    "ylab = \"Total counts\" if SCALE_PER is None else f\"Counts per {SCALE_PER:,} cells\"\n",
    "\n",
    "with PdfPages(OUT_COMBINED_PDF) as bigpdf:\n",
    "    for gene_key in gene_keys_sorted:\n",
    "        title = ensg_to_display.get(gene_key, str(gene_key))\n",
    "        sub = df_counts[df_counts[\"GeneKey\"] == gene_key]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        txs = sorted(sub[\"TranscriptLabel\"].unique().tolist())\n",
    "        full_idx = pd.MultiIndex.from_product([txs, subct_order], names=[\"TranscriptLabel\",\"sub_cell_type\"])\n",
    "        sub_grid = (sub.groupby([\"TranscriptLabel\",\"sub_cell_type\"], observed=True)[\"raw_counts\"]\n",
    "                        .sum()\n",
    "                        .reindex(full_idx, fill_value=0)\n",
    "                        .reset_index())\n",
    "\n",
    "        tx_order = (sub.groupby(\"TranscriptLabel\", observed=True)[\"raw_counts\"]\n",
    "                        .sum().sort_values(ascending=False).index.tolist())\n",
    "\n",
    "        sub_grid[\"TranscriptLabel\"]  = pd.Categorical(sub_grid[\"TranscriptLabel\"],  categories=tx_order, ordered=True)\n",
    "        sub_grid[\"sub_cell_type\"]    = pd.Categorical(sub_grid[\"sub_cell_type\"],    categories=subct_order, ordered=True)\n",
    "\n",
    "        n_tx = len(tx_order)\n",
    "        fig_w = max(6, min(0.4 * n_tx + 2, 18))\n",
    "        fig_h = max(4, min(0.28 * n_tx + 2, 12))\n",
    "        fig, ax = plt.subplots(figsize=(fig_w, fig_h), constrained_layout=True)\n",
    "\n",
    "        # manual stacked bars by sub-cell-type\n",
    "        bottoms = np.zeros(len(tx_order), dtype=float)\n",
    "        for ct in subct_order:\n",
    "            vals = (sub_grid.loc[sub_grid[\"sub_cell_type\"] == ct, [\"TranscriptLabel\",\"raw_counts\"]]\n",
    "                            .set_index(\"TranscriptLabel\")\n",
    "                            .reindex(tx_order)[\"raw_counts\"].to_numpy())\n",
    "            ax.bar(tx_order, vals, bottom=bottoms,\n",
    "                   color=palette.get(ct, \"#999999\"), edgecolor=\"black\", label=ct)\n",
    "            bottoms += vals\n",
    "\n",
    "        ax.set_xlabel(\"Transcripts\")\n",
    "        ax.set_ylabel(ylab)\n",
    "        ax.set_title(title)\n",
    "\n",
    "        ax.tick_params(axis=\"x\", labelsize=8, rotation=40)\n",
    "        for lbl in ax.get_xticklabels():\n",
    "            lbl.set_horizontalalignment(\"right\")\n",
    "\n",
    "        sns.despine(ax=ax, top=True, right=True)\n",
    "        ax.legend(title=\"Sub-cell type\", bbox_to_anchor=(1.01, 1), loc=\"upper left\", frameon=True)\n",
    "\n",
    "        out_path = os.path.join(OUT_DIR_PER_GENE, f\"{safe_name(title)}.pdf\")\n",
    "        fig.savefig(out_path, dpi=600, transparent=True, bbox_inches=\"tight\")\n",
    "        saved_pages.append(out_path)\n",
    "        bigpdf.savefig(fig, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "print(f\"[info] Wrote {len(saved_pages)} per-gene PDFs to {OUT_DIR_PER_GENE}\")\n",
    "print(f\"[info] Combined multi-page PDF: {OUT_COMBINED_PDF}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
